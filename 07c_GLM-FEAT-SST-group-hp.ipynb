{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys                               # system functions\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "from nipype.interfaces.io import DataSink\n",
    "import nipype.interfaces.fsl as fsl          # fsl\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "import errno\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "# updating nipype from 1.7.0 -> 1.8.1, will hopefully ifx no PE estimates founds error # didn't fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copes at level 2:\n",
    "##### Model 0:\n",
    "1. FS\n",
    "2. SS\n",
    "3. Go\n",
    "4. FS-Go\n",
    "5. FS-SS\n",
    "6. SS-Go\n",
    "\n",
    "##### Model 1:\n",
    "1. response_left\n",
    "2. response_right\n",
    "3. response_left-response_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sstsubs = sorted(glob.glob(os.path.join('/home/Public/trondheim', 'derivatives', 'glm_feat_hp_sct', 'subject_level_model', 'sub-*', 'ses-sstmsit', 'func','fwhm-1p5','model-0','*task-sst_space-MNI*contrast-0_desc-zstat*')))\n",
    "print(f'Group level based on {len(sstsubs)} subjects\\n')\n",
    "print([x.split('/')[-2].split('-')[-1] for x in sorted(glob.glob(os.path.join('/home/Public/trondheim', 'derivatives', 'fmriprep','fmriprep', 'sub-*', 'ses-sstmsit')))])\n",
    "\n",
    "sst = [x.split('/')[-6].split('-')[-1] for x in sstsubs]\n",
    "allsst = [x.split('/')[-2].split('-')[-1] for x in sorted(glob.glob(os.path.join('/home/Public/trondheim', 'sourcedata', 'zipdata', 'sub-*', 'ses-sstmsit')))]\n",
    "print(f'\\nsubs {sorted(list(set(allsst) - set(sst)))} are missing')\n",
    "\n",
    "# remove subs who did it wrong\n",
    "# to_remove = ['004', '010', '008', '019', '013', '027']\n",
    "print(f\"\\nsubs: {(to_remove := sorted(['004', '010', '008', '019', '013', '027']))} were excluded\")\n",
    "\n",
    "print(f'\\ncomplete sub list is (n={len((fin_sub := [x for x in allsst if x not in to_remove]))}):\\n\\n {fin_sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general set-up\n",
    "project_folder = '/home/Public/trondheim'\n",
    "work_dir = os.path.join(project_folder, 'processing', 'nipype_workflow_folders')\n",
    "# The directory where we can find the level 2 output\n",
    "slm_folder = os.path.join(project_folder, 'derivatives', 'glm_feat_hp_sct', 'subject_level_model')\n",
    "\n",
    "\n",
    "spaces = ['T1w']   # shouldn't touch this but just in case we _do_ want to go back to MNI....\n",
    "ses = 'sstmsit'      # don't make this a list, that won't work\n",
    "task = 'sst'     # don't make this a list, that won't work\n",
    "model_ns = ['0']      # \n",
    "fwhms = ['1p5']#, '4p5']\n",
    "\n",
    "template_brain = '/home/Public/trondheim/sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii'\n",
    "template_brain_mask = '/home/Public/trondheim/sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain_mask.nii'\n",
    "\n",
    "# subject_ids = sorted(glob.glob(os.path.join(project_folder, 'derivatives', 'glm_feat', 'subject_level_model', 'sub-*', f'ses-{ses}')))\n",
    "# subject_ids = sorted(glob.glob(os.path.join('/home/Public/trondheim', 'derivatives', 'glm_feat_hp', 'subject_level_model', 'sub-*', 'ses-sstmsit', 'func','fwhm-1p5',f'model-{model_ns}','*task-sst_space-MNI*contrast-0_desc-zstat*')))\n",
    "# subject_ids = [x.split('/')[-6].split('-')[-1] for x in subject_ids]\n",
    "# subject_ids = [x for x in subject_ids if x not in ['021','023','024','026','036']]\n",
    "subject_ids = fin_sub\n",
    "\n",
    "if model_ns[0] == '0':\n",
    "    contrasts = ['0','1','2','3','4','5']  # task from second level model\n",
    "#     contrasts = ['3','4','5']\n",
    "#     contrasts = ['0']\n",
    "elif model_ns[0] == '1':\n",
    "    contrasts = ['0','1','2'] # motor from second level model\n",
    "\n",
    "\n",
    "templates = {'level2_cope': os.path.join(slm_folder, 'sub-*', f'ses-{ses}', 'func', 'fwhm-{fwhm}', 'model-{model_n}', '*ses-sstmsit_task-sst_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-cope.nii.gz'),\n",
    "             'level2_varcope': os.path.join(slm_folder, 'sub-*', f'ses-{ses}', 'func', 'fwhm-{fwhm}', 'model-{model_n}', '*ses-sstmsit_task-sst_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-varcope.nii.gz'),\n",
    "             'level2_tdof': os.path.join(slm_folder, 'sub-*', f'ses-{ses}', 'func', 'fwhm-{fwhm}', 'model-{model_n}', '*ses-sstmsit_task-sst_space-MNI152NLin2009cAsym_model-{model_n}_contrast-{contrast_n}_desc-tdof_t.nii.gz')}\n",
    "\n",
    "## if uneven number of template / designs / subs the code will crash\n",
    "print(f\"no.copes = {len(glob.glob(templates['level2_cope'].format(fwhm=fwhms[0],model_n=model_ns[0],contrast_n=0)))}\")\n",
    "print(f\"no.varvopes = {len(glob.glob(templates['level2_varcope'].format(fwhm=fwhms[0],model_n=model_ns[0],contrast_n=0)))}\")\n",
    "print(f\"no.tdofs = {len(glob.glob(templates['level2_tdof'].format(fwhm=fwhms[0],model_n=model_ns[0],contrast_n=0)))}\")\n",
    "\n",
    "print(subject_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subject_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## make brain mask for flameo\n",
    "# import nilearn\n",
    "# from nilearn import plotting\n",
    "# import nibabel as nib\n",
    "\n",
    "# hdr = nib.load('../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii')\n",
    "# brain_data = hdr.get_fdata()\n",
    "# brain_data[brain_data>0] = 1\n",
    "# brain_mask = nib.Nifti1Image(brain_data, affine=hdr.affine, header=hdr.header)\n",
    "# brain_mask.to_filename('../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "workflow = pe.Workflow(name='feat_level3_sst_hp')\n",
    "workflow.base_dir = os.path.join(project_folder, 'processing', 'nipype_workflow_folders')\n",
    "workflow.config = {\"execution\": {\"crashdump_dir\":os.path.join(project_folder, 'processing', 'crashdumps')}}\n",
    "\n",
    "# Identity\n",
    "identity = pe.Node(util.IdentityInterface(fields=['contrast_n', 'model_n', 'fwhm']), name='identity')\n",
    "identity.iterables = [('contrast_n', contrasts),\n",
    "                      ('fwhm', fwhms),\n",
    "                      ('model_n', model_ns)]\n",
    "\n",
    "# Selector\n",
    "selector = pe.Node(nio.SelectFiles(templates), name='selector')\n",
    "workflow.connect(identity, 'contrast_n', selector, 'contrast_n')\n",
    "workflow.connect(identity, 'fwhm', selector, 'fwhm')\n",
    "workflow.connect(identity, 'model_n', selector, 'model_n')\n",
    "\n",
    "## Merge copes, varcopes, masks\n",
    "copemerge    = pe.Node(interface=fsl.Merge(dimension='t'),\n",
    "                          name=\"copemerge\")\n",
    "\n",
    "varcopemerge = pe.Node(interface=fsl.Merge(dimension='t'),\n",
    "                       name=\"varcopemerge\")\n",
    "\n",
    "workflow.connect(selector, 'level2_cope', copemerge, 'in_files')\n",
    "workflow.connect(selector, 'level2_varcope', varcopemerge, 'in_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_ids():\n",
    "    import glob\n",
    "    import os\n",
    "    subject_ids = sorted(glob.glob(os.path.join('/home/Public/trondheim', 'derivatives', 'glm_feat_hp_sct', 'subject_level_model', 'sub-*', 'ses-sstmsit', 'func','fwhm-1p5','model-1','*task-sst_space-MNI*contrast-0_desc-zstat*')))\n",
    "    subject_ids = [x.split('/')[-6].split('-')[-1] for x in subject_ids]\n",
    "    to_remove = ['004', '010', '008', '019', '013', '027']\n",
    "    subject_ids =  [x for x in subject_ids if x not in to_remove]\n",
    "    print(f'number of subs: {len(subject_ids)}')\n",
    "    return subject_ids\n",
    "\n",
    "subject_id_getter = pe.Node(util.Function(output_names=['subject_ids'],\n",
    "                                          function=get_subject_ids),\n",
    "                            name='subject_id_getter')\n",
    "\n",
    "def get_design_matrix(second_level_contrast, subject_ids): #=subject_ids):\n",
    "    print(second_level_contrast)\n",
    "    regressors = {'intercept': [1 for x in range(len(subject_ids))]}\n",
    "    \n",
    "    # contrasts (3rd-level)\n",
    "    third_level_contrasts = [('Group mean', 'T', ['intercept'], [1.0]),\n",
    "                             ('-Group mean', 'T', ['intercept'], [-1.0])\n",
    "                             ]\n",
    "    \n",
    "    return third_level_contrasts, regressors\n",
    "\n",
    "\n",
    "contrastgen_l3 = pe.Node(util.Function(input_names=['second_level_contrast', 'subject_ids'],\n",
    "                                       output_names=['third_level_contrasts', 'regressors'],\n",
    "                                       function=get_design_matrix),\n",
    "                      name='contrastgen_l3')\n",
    "\n",
    "level3model = pe.Node(interface=fsl.MultipleRegressDesign(),\n",
    "                      name='l3model')\n",
    "\n",
    "\n",
    "workflow.connect(subject_id_getter, 'subject_ids', contrastgen_l3, 'subject_ids')\n",
    "workflow.connect(identity, 'contrast_n', contrastgen_l3, 'second_level_contrast')\n",
    "workflow.connect(contrastgen_l3, 'third_level_contrasts', level3model, 'contrasts')\n",
    "workflow.connect(contrastgen_l3, 'regressors', level3model, 'regressors')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flameo = pe.Node(\n",
    "#     interface=fsl.FLAMEO(run_mode='flame1'),\n",
    "#     name=\"flame1\")\n",
    "\n",
    "# flameo.inputs.mask_file = template_brain_mask\n",
    "\n",
    "# workflow.connect([\n",
    "#     (copemerge, flameo, [('merged_file', 'cope_file')]),\n",
    "#     (varcopemerge, flameo, [('merged_file', 'var_cope_file')]),\n",
    "#     (level3model, flameo, [('design_mat', 'design_file'),\n",
    "#                            ('design_con', 't_con_file'), \n",
    "#                            ('design_grp', 'cov_split_file')]),\n",
    "# ])\n",
    "\n",
    "flameo = pe.Node(\n",
    "    interface=fsl.FLAMEO(),\n",
    "    name=\"flameo\")\n",
    "\n",
    "flameo.iterables = ('run_mode', ['flame1', 'flame12'])\n",
    "flameo.inputs.mask_file = template_brain_mask\n",
    "flameo.inputs.infer_outliers = False   # run with automatic outlier detection\n",
    "\n",
    "workflow.connect([\n",
    "    (copemerge, flameo, [('merged_file', 'cope_file')]),\n",
    "    (varcopemerge, flameo, [('merged_file', 'var_cope_file')]),\n",
    "    (level3model, flameo, [('design_mat', 'design_file'),\n",
    "                           ('design_con', 't_con_file'), \n",
    "                           ('design_grp', 'cov_split_file')]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster thresholding\n",
    "# Smoothness estimation\n",
    "smoothestimate = pe.MapNode(fsl.SmoothEstimate(), iterfield=['zstat_file'], name='smoothestimate')\n",
    "smoothestimate.inputs.mask_file = template_brain_mask\n",
    "\n",
    "workflow.connect(flameo, 'zstats', smoothestimate, 'zstat_file')\n",
    "\n",
    "# get volume\n",
    "get_volume = pe.Node(fsl.ImageStats(op_string = '-V'), name='get_volume')\n",
    "get_volume.inputs.in_file = template_brain_mask\n",
    "\n",
    "\n",
    "# Cluster threshold\n",
    "grf_cluster = pe.MapNode(fsl.Cluster(), iterfield=['dlh', 'in_file'], name='grf_cluster')\n",
    "grf_cluster.iterables = [(\"threshold\", [2.3, 3.1])]\n",
    "grf_cluster.inputs.out_localmax_txt_file = True\n",
    "grf_cluster.inputs.pthreshold = 0.05\n",
    "grf_cluster.inputs.out_index_file = True\n",
    "grf_cluster.inputs.out_threshold_file = True\n",
    "\n",
    "\n",
    "def volume_convert(input):\n",
    "    return int(input[0])\n",
    "\n",
    "workflow.connect(get_volume, ('out_stat', volume_convert), grf_cluster, 'volume')\n",
    "workflow.connect(smoothestimate, 'dlh', grf_cluster, 'dlh')\n",
    "workflow.connect(flameo, 'zstats', grf_cluster, 'in_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Datasink\n",
    "# datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "# datasink.inputs.base_directory=os.path.join(project_folder, 'derivatives', \"glm_feat\", \"group_level_model\", \"ses-sstmsit\",\"task-sst\")\n",
    "\n",
    "# workflow.connect(copemerge, 'merged_file', datasink, 'copes_merged')\n",
    "# workflow.connect(level3model, 'design_con', datasink, 'design_con')\n",
    "# workflow.connect(level3model, 'design_mat', datasink, 'design_mat')\n",
    "\n",
    "# ## todo: substitutions\n",
    "# workflow.connect(flameo, 'zstats', datasink, 'third_level_model.level3_zstats')\n",
    "# workflow.connect(flameo, 'copes', datasink, 'third_level_model.level3_copes')\n",
    "# workflow.connect(flameo, 'var_copes', datasink, 'third_level_model.level3_varcopes')\n",
    "# workflow.connect(flameo, 'tdof', datasink, 'third_level_model.level3_tdof_ts')\n",
    "\n",
    "# ## cluster results\n",
    "# workflow.connect(grf_cluster, 'threshold_file', datasink, 'grf_thresholded_zstats_file')\n",
    "# workflow.connect(grf_cluster, 'localmax_txt_file', datasink, 'grf_localmax_txt_file')\n",
    "# workflow.connect(grf_cluster, 'index_file', datasink, 'cluster_indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasink\n",
    "datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "datasink.inputs.base_directory=os.path.join(project_folder, 'derivatives', \"glm_feat_hp_sct\", \"group_level_model\", \"ses-sstmsit\",\"task-sst\",\"model-1\",'model-1')\n",
    "\n",
    "substitutions_regexp = [(r'third_level_model/grf_thresholded_zstats_file/_contrast_n_(\\d+)_fwhm_(\\S{3})_model_n_(\\S+)/_run_mode_flame(\\d+)/_threshold_(\\S+)/_grf_cluster(\\d)/(\\S+)(\\d)_threshold.nii.gz',\n",
    "                         'model-\\\\3/model-\\\\3_fwhm-\\\\2_subjectlevelcontrast-\\\\1_grouplevelcontrast-\\\\8_flame-\\\\4_desc-\\\\7_voxelthreshold-\\\\5.nii.gz'),\n",
    "                        (r'third_level_model/level3_.*/_contrast_n_(\\d+)_fwhm_(\\S{3})_model_n_(\\S+)/_run_mode_flame(\\d+)/(\\S+)(\\d).nii.gz',\n",
    "                          'model-\\\\3/model-\\\\3_fwhm-\\\\2_subjectlevelcontrast-\\\\1_grouplevelcontrast-\\\\6_flame-\\\\4_desc-\\\\5.nii.gz'),\n",
    "                        # (r'third_level_model/grf_localmax_.*/fwhm-(\\S{3})/model-(\\S+)/contrast-(\\d+)/_run_mode_flame(\\d+)/_threshold_(\\S+)/_grf_cluster(\\d)/zstat1_(\\S+).txt',\n",
    "                        #   'model-\\\\2/model-\\\\2_fwhm-\\\\1_subjectlevelcontrast-\\\\3_grouplevelcontrast-\\\\6_flame-\\\\4_desc-zstat_\\\\7-voxelthreshold-\\\\5.txt')\n",
    "                       ]\n",
    "\n",
    "datasink.inputs.regexp_substitutions = substitutions_regexp\n",
    "\n",
    "## todo: substitutions\n",
    "workflow.connect(flameo, 'zstats', datasink, 'third_level_model.level3_zstats')\n",
    "workflow.connect(flameo, 'copes', datasink, 'third_level_model.level3_copes')\n",
    "workflow.connect(flameo, 'var_copes', datasink, 'third_level_model.level3_varcopes')\n",
    "workflow.connect(flameo, 'tdof', datasink, 'third_level_model.level3_tdof_ts')\n",
    "\n",
    "## cluster results\n",
    "workflow.connect(grf_cluster, 'threshold_file', datasink, 'third_level_model.grf_thresholded_zstats_file')\n",
    "workflow.connect(grf_cluster, 'localmax_txt_file', datasink, 'third_level_model.grf_localmax_txt_file')\n",
    "workflow.connect(grf_cluster, 'index_file', datasink, 'third_level_model.grf_cluster_indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workflow.run(plugin='MultiProc', plugin_args={'n_procs': 20, 'memory_gb': 200})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
