{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's check three things in the fMRI data\n",
    "1. tSNR (of preprocessed data)\n",
    "2. left > right button presses t-test\n",
    "3. Physiological noise regression F-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "\n",
    "import mkl\n",
    "mkl.set_num_threads(4)   # by default, use 4 threads for NP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nilearn\n",
    "from nilearn import plotting, image\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import nibabel as nib\n",
    "from nipype.interfaces import ants\n",
    "import nighres\n",
    "\n",
    "# simple modeling\n",
    "from nilearn.glm.first_level import FirstLevelModel #nilearn must be -v >= 0.7.0\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils import apply_warp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rois(sub, atlas_name='ATAG', space='T1w'):\n",
    "    if atlas_name == 'ATAG':\n",
    "        if space == 'MNI152NLin2009cAsym' or space == 'mni':\n",
    "            ### Rois in MNI09c-space\n",
    "            mask_dir='/home/Public/trondheim/sourcedata/masks/MNI152NLin2009cAsym_res-1p5'\n",
    "            fns = sorted(glob.glob(mask_dir + '/space-*'))\n",
    "            names = [re.match('.*space-(?P<space>[a-zA-Z0-9]+)_res-1p5_label-(?P<label>[a-zA-Z0-9]+)_probseg_def-img.nii.gz', fn).groupdict()['label'] for fn in fns]\n",
    "        else:\n",
    "            mask_dir = f'../derivatives/masks_atag_func/sub-{sub}/anat/sub-{sub}_*.nii.gz'\n",
    "            fns = sorted(glob.glob(mask_dir))\n",
    "            names = [re.match('.*space-(?P<space>[a-zA-Z0-9]+)_desc-mask-(?P<label>[a-zA-Z0-9]+).nii.gz', fn).groupdict()['label'] for fn in fns]\n",
    "    elif atlas_name == 'MASSP':\n",
    "        mask_dir = f'../derivatives/masks_massp_func/sub-{sub}/anat/sub-{sub}_*.nii.gz'\n",
    "        fns = sorted(glob.glob(mask_dir))\n",
    "        names = [re.match('.*space-(?P<space>[a-zA-Z0-9]+)_desc-mask-(?P<label>\\S+).nii.gz', fn).groupdict()['label'] for fn in fns]\n",
    "    elif atlas_name == 'thalamus':\n",
    "        mask_dir = f'../derivatives/masks_thal_func/sub-{sub}/anat/sub-{sub}_*.nii.gz'\n",
    "        fns = sorted(glob.glob(mask_dir))\n",
    "        names = [re.match('.*space-(?P<space>[a-zA-Z0-9]+)_desc-mask-(?P<label>.*).nii.gz', fn).groupdict()['label'] for fn in fns]\n",
    "\n",
    "    roi_dict = dict(zip(names, fns))\n",
    "    return roi_dict\n",
    "\n",
    "def load_atlas(sub, atlas_name='MASSP', space='T1w'):\n",
    "    from nilearn import image\n",
    "    \n",
    "    roi_dict = find_rois(sub, atlas_name, space)\n",
    "    combined = image.concat_imgs(roi_dict.values())\n",
    "    \n",
    "    class AttrDict(dict):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super(AttrDict, self).__init__(*args, **kwargs)\n",
    "            self.__dict__ = self\n",
    "            \n",
    "    roi_atlas = AttrDict({'maps': combined,\n",
    "                          'labels': roi_dict.keys()})\n",
    "    \n",
    "    return roi_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = '011'\n",
    "# boldref = sorted(glob.glob(f'../derivatives/fmriprep/fmriprep/sub-{sub}/ses-*/func/sub-{sub}_ses-*_task-*_run-*_space-T1w_boldref.nii.gz'))[0]\n",
    "# nilearn.plotting.plot_prob_atlas(load_atlas(sub).maps, bg_img=boldref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. tSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for tSNR\n",
    "def high_pass(nii, verbose=False, mask=None):\n",
    "#     print('Highpass-filtering')\n",
    "    t_r = nii.header['pixdim'][4]\n",
    "    if mask is not None:\n",
    "        hp_masker = NiftiMasker(mask, high_pass=1./128, t_r=t_r)\n",
    "    else:\n",
    "        hp_masker = NiftiMasker(high_pass=1./128, t_r=t_r)\n",
    "    \n",
    "    # Generate & fit NiftiMasker\n",
    "    hp_data = hp_masker.fit_transform(nii)\n",
    "    \n",
    "    # back to brain space\n",
    "    inver = hp_masker.inverse_transform(hp_data)\n",
    "\n",
    "    # add mean of timeseries per voxel back\n",
    "    highpassed_data = inver.get_fdata() + np.mean(nii.get_fdata(), 3)[:,:,:,np.newaxis]\n",
    "    highpassed_img = nib.Nifti1Image(highpassed_data, inver.affine, header=nii.header)\n",
    "    \n",
    "    return highpassed_img\n",
    "\n",
    "def make_tsnr_image(nii, exclude_volumes=4):\n",
    "    ''' exclude_volumes: how many (non-steady state) volumes at the beginning of the run should be excluded?'''\n",
    "#     print('Calculating tSNR')\n",
    "    mean_ = nilearn.image.math_img('nii[:,:,:,{}:].mean(-1)'.format(exclude_volumes), nii=nii)\n",
    "    std_ = nilearn.image.math_img('nii[:,:,:,{}:].std(-1)'.format(exclude_volumes), nii=nii)\n",
    "    tsnr = nilearn.image.math_img('nii[:,:,:,{}:].mean(-1)/nii[:,:,:,{}:].std(-1)'.format(exclude_volumes,exclude_volumes), nii=nii)\n",
    "    \n",
    "    return tsnr, mean_, std_\n",
    "\n",
    "## extracting value from mask\n",
    "def get_roi_weighted_average(nii, atlas):\n",
    "    data = nii.get_fdata()\n",
    "    \n",
    "    # identify voxels that shouldn't be weighted: cnr/tsnr can't be <0, >1000, or nan.\n",
    "    # these can arise, mostly at the edges of the brain, due to numerical issues (T2* estimation, division by small noise, etc)\n",
    "    bad_voxel_idx = (data < 0) | (data > 100000) | np.isnan(data)\n",
    "    \n",
    "    # set to 0 in data\n",
    "    data[bad_voxel_idx] = 0\n",
    "    \n",
    "    out = pd.Series(index=pd.Index(atlas.labels))\n",
    "    for mask_id in np.arange(atlas.maps.shape[-1]):\n",
    "        # get in mask\n",
    "        mask_label = [x for x in atlas.labels][mask_id]\n",
    "\n",
    "        this_mask = image.index_img(atlas.maps, mask_id).get_fdata()\n",
    "        this_mask[bad_voxel_idx] = 0  # bad values, don't weigh these\n",
    "        this_mask[this_mask<0.01] = 0  # prevent negative weights\n",
    "        \n",
    "        if this_mask.sum() > 0:\n",
    "            val_weighted = np.average(data, weights=this_mask)  # inf * 0 = np.nan -> manually set np.nans to 0\n",
    "        else:\n",
    "            val_weighted = 0\n",
    "        out[mask_label] = val_weighted\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsnr(fn, overwrite_hp=False, overwrite_tsnr=False):\n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)_ses-(?P<ses>\\S+)_task-(?P<task>\\S+)_run-(?P<run>\\d)_space-T1w_desc-preproc_bold.*')\n",
    "    gd = regex.match(fn).groupdict()\n",
    "#     print(fn)\n",
    "#     print(gd)\n",
    "    brain_mask = nib.load(fn.replace('preproc_bold', 'brain_mask'))\n",
    "\n",
    "    # has this file been highpassed?\n",
    "    hp_save_fn = fn.replace('fmriprep/fmriprep', 'high_passed_func')\n",
    "    if os.path.exists(hp_save_fn) and not overwrite_hp:\n",
    "        hp_data = nib.load(hp_save_fn)\n",
    "    else:\n",
    "        nii = nib.load(fn)\n",
    "        print('Highpass-filtering {}'.format(fn.split('/')[-1]))\n",
    "        hp_data = high_pass(nii, mask=brain_mask)\n",
    "        os.makedirs(os.path.dirname(hp_save_fn), exist_ok=True)\n",
    "        hp_data.to_filename('../derivatives/high_passed_func/sub-{}/ses-{}/func/{}'.format(gd['sub'], gd['ses'], os.path.basename(fn)))\n",
    "\n",
    "    # Has tsnr nii already been created?\n",
    "    tsnr_save_fn = fn.replace('fmriprep/fmriprep', 'tsnr').replace('desc-preproc_bold', 'desc-tsnr')\n",
    "    if os.path.exists(tsnr_save_fn) and not overwrite_tsnr:\n",
    "        tsnr = nib.load(tsnr_save_fn)\n",
    "    else:\n",
    "        print('Calculating tSNR of {}'.format(tsnr_save_fn.split('/')[-1]))\n",
    "        tsnr, mean_, std_ = make_tsnr_image(hp_data)\n",
    "        os.makedirs(os.path.dirname(tsnr_save_fn), exist_ok=True)\n",
    "        \n",
    "        tsnr.to_filename(tsnr_save_fn)\n",
    "        mean_.to_filename(tsnr_save_fn.replace('-tsnr', '-mean'))\n",
    "        std_.to_filename(tsnr_save_fn.replace('-tsnr', '-std'))\n",
    "    \n",
    "    # extract values and save to csv\n",
    "    for atlas_name in ['MASSP', 'ATAG', 'thalamus']:\n",
    "        fn_out = f'../derivatives/tsnr/sub-{{sub}}/ses-{{ses}}/func/sub-{{sub}}_ses-{{ses}}_task-{{task}}_run-{{run}}_space-T1w_desc-{atlas_name}-tsnrvalues.tsv'.format(**gd)\n",
    "        \n",
    "        if os.path.exists(fn_out) and not overwrite_tsnr:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            atlas = load_atlas(sub=gd['sub'], atlas_name=atlas_name, space='T1w')\n",
    "        except:\n",
    "            # not all subs have MASSP labels yet\n",
    "            \n",
    "            continue\n",
    "        print(gd)\n",
    "#         if not (tsnr.affine == atlas.maps.affine).all():\n",
    "#             print('Atlas and tSNR map do not have the same affine, rerun highpassing & tsnr creation! {}'.format(fn))\n",
    "#             return atlas, tsnr\n",
    "#             break\n",
    "#         print(atlas_name)\n",
    "        tsnr_table = pd.DataFrame(get_roi_weighted_average(tsnr, atlas=atlas)).T\n",
    "        tsnr_table['subject'] = gd['sub']\n",
    "        tsnr_table['session'] = gd['ses']\n",
    "        tsnr_table['task'] = gd['task']\n",
    "        tsnr_table['run'] = gd['run']\n",
    "        tsnr_table.set_index(['subject', 'session', 'task', 'run'])\n",
    "        \n",
    "        tsnr_table.to_csv(fn_out, sep='\\t', index=False)\n",
    "    \n",
    "    # warp to MNI\n",
    "    fn_mni_space = tsnr_save_fn.replace('T1w', 'MNI152NLin2009cAsym')\n",
    "    if (not os.path.exists(fn_mni_space)) or overwrite_tsnr:\n",
    "        tsnr_warped = apply_warp(tsnr_save_fn, sub=gd['sub'])\n",
    "        os.rename(tsnr_warped, fn_mni_space)\n",
    "        \n",
    "        mean_warped = apply_warp(tsnr_save_fn.replace('-tsnr', '-mean'), sub=gd['sub'])\n",
    "        os.rename(mean_warped, fn_mni_space.replace('-tsnr', '-mean'))\n",
    "        \n",
    "        std_warped = apply_warp(tsnr_save_fn.replace('-tsnr', '-std'), sub=gd['sub'])\n",
    "        os.rename(std_warped, fn_mni_space.replace('-tsnr', '-std'))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_funcs = sorted(glob.glob('../derivatives/fmriprep/fmriprep/sub-*/ses*/func/*T1w*_bold.nii.gz'))\n",
    "# subs = ['002','003','004','005','006','007','008','009','010','011']\n",
    "\n",
    "# subs = ['012','013','014','015','016','017','018','019','020','021']\n",
    "# subs = ['022','023','024','025','026']\n",
    "# subs = all_subjects = ['027','029','030','031','032']\n",
    "subs=['026']\n",
    "\n",
    "all_funcs = [x for x in all_funcs if x.split('/')[4].split('-')[1] in subs]\n",
    "all_funcs = [x for x in all_funcs if 'sstmsit' in x]\n",
    "all_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_funcs = sorted(glob.glob('../derivatives/fmriprep/fmriprep/sub-*/ses*/func/*T1w*_bold.nii.gz'))\n",
    "# all_funcs = [x for x in all_funcs if not 'sub-001' in x]\n",
    "# all_funcs = all_funcs[:250]\n",
    "\n",
    "# all_funcs = [x for x in all_funcs if 'anatomical' in x]\n",
    "# n_jobs = number of cores - BE CAREFUL OF MEMORY LOAD! Each process takes ~5% of available RAM\n",
    "# Parallel(n_jobs=12, verbose=1)(delayed(get_tsnr)(x) for x in all_funcs)\n",
    "\n",
    "def get_tsnr_catch(func):\n",
    "    try:\n",
    "        get_tsnr(func, overwrite_hp=True, overwrite_tsnr=False)\n",
    "        return 0\n",
    "    except:\n",
    "        return '{} FAILED'.format(func)\n",
    "\n",
    "# old stuff\n",
    "with mp.Pool(10) as p:   #- BE CAREFUL OF MEMORY LOAD! Each process takes ~5% of available RAM # sometimes hangs??(sct) \n",
    "    p.map(get_tsnr_catch, all_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for func in all_funcs:\n",
    "#     print(func)\n",
    "#     get_tsnr(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All tSNR estimates found\n",
    "for atlas_name in ['MASSP', 'ATAG', 'thalamus']:\n",
    "    all_tsnr_tables_fn = sorted(glob.glob(f'../derivatives/tsnr/sub-*/ses-*/func/sub-*_ses-*_task-*_run-*_space-T1w_desc-{atlas_name}-tsnrvalues.tsv'))\n",
    "    all_tsnr_table = pd.concat([pd.read_csv(x, sep='\\t', index_col=['subject', 'session', 'task', 'run']) for x in all_tsnr_tables_fn]) #.set_index(['subject', 'session', 'task', 'run'])\n",
    "    all_tsnr_table.to_csv(f'../derivatives/tsnr/all_tsnrs_{atlas_name}_table.tsv', sep='\\t')\n",
    "#    all_tsnr_table\n",
    "\n",
    "    fg = sns.catplot(x='ROI', y='tSNR', data=all_tsnr_table.reset_index().melt(id_vars=['subject', 'session', 'task', 'run'], var_name='ROI', value_name='tSNR'))\n",
    "    plt.gcf().set_size_inches(15,5)\n",
    "    plt.gcf().savefig(f'../figures/tsnr-{atlas_name}.pdf', bbox_inches='tight')\n",
    "\n",
    "    display(all_tsnr_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RETROICOR estimation\n",
    "1. Run PhysIO to get RETROICOR, HRV and RVT\n",
    "\n",
    "unfortunately we need to call matlab for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_physLog_file(subject_n, session_n):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_matlab_args(subject_n, session_n, task, run, overwrite=0):\n",
    "    info_file = '/home/Public/trondheim/derivatives/phys_log/sub-{subject_n}/ses-{session_n}/func/sub-{subject_n}_ses-{session_n}_task-{task}_run-{run}_Info.log'.format(**locals())\n",
    "    puls_file = '/home/Public/trondheim/derivatives/phys_log/sub-{subject_n}/ses-{session_n}/func/sub-{subject_n}_ses-{session_n}_task-{task}_run-{run}_PULS.log'.format(**locals())\n",
    "    resp_file = '/home/Public/trondheim/derivatives/phys_log/sub-{subject_n}/ses-{session_n}/func/sub-{subject_n}_ses-{session_n}_task-{task}_run-{run}_RESP.log'.format(**locals())\n",
    "    \n",
    "    if os.path.isfile(info_file) and os.path.isfile(puls_file) and os.path.isfile(resp_file):\n",
    "        print(f'Log files for {subject_n} {session_n} {task} {run} exist')\n",
    "    else:\n",
    "        print(f'Log files for {subject_n} {session_n} {task} {run} do not exist')\n",
    "        \n",
    "    nii = nib.load(info_file.replace('Info.log', 'bold.nii.gz').replace('phys_log', 'bids'))\n",
    "    n_vols = nii.header['dim'][4]\n",
    "    n_slices = nii.header['dim'][3]\n",
    "    t_r = nii.header['pixdim'][4]\n",
    "    per_slice = 0\n",
    "    save_dir = os.path.dirname(info_file).replace('phys_log', 'retroicor')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f'saving to {save_dir}')\n",
    "    \n",
    "    mlcode = '\\\"cd(\\'/home/Public/trondheim/scripts/matlabshit\\'); addpath(\\'/home/Public/trondheim/scripts/matlabshit/tapas-master/PhysIO/code\\'); run_physIO(\\'{puls_file}\\', \\'{resp_file}\\', \\'{info_file}\\', {n_vols}, {n_slices}, {t_r}, \\'{save_dir}\\', {per_slice}, {overwrite}); exit\\\"'.format(**locals())\n",
    "    return mlcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_to_run(return_tuples=False):\n",
    "    # if you want to run everything...\n",
    "#    all_phys_files = sorted(glob.glob('../derivatives/bids/sub-*/ses-*/func/*_physio.tsv.gz'))\n",
    "#    all_phys_files = [x for x in all_phys_files if not 'recording-' in x]\n",
    "#    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-(?P<run>\\d).*_physio.tsv.gz')\n",
    "\n",
    "    all_phys_files = sorted(glob.glob('../derivatives/phys_log/sub-*/ses-*/func/*_Info.log'))\n",
    "#     all_phys_files = [x for x in all_phys_files if not 'recording-' in x]\n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-(?P<run>\\d)_Info.log')\n",
    "    \n",
    "    all_phys_files_dict = [regex.match(x).groupdict() for x in all_phys_files]\n",
    "    all_phys_files_df = pd.DataFrame.from_dict(all_phys_files_dict).sort_values(['sub','ses','task', 'run']).drop_duplicates()\n",
    "    \n",
    "    dict_list = all_phys_files_df.to_dict(orient='records')\n",
    "    if return_tuples:\n",
    "        return [tuple(x.values()) for x in dict_list]\n",
    "    else:\n",
    "        return dict_list\n",
    "\n",
    "def find_which_to_run():\n",
    "    # finds all runs for which there are RETROICOR regressors, and removes those for which there's an output already\n",
    "    all_phys_files = find_all_to_run()\n",
    "    \n",
    "    to_run = []\n",
    "    for dict_ in all_phys_files:\n",
    "        fp = '../derivatives/retroicor/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-retroicor_regressors.tsv'.format(**dict_)\n",
    "        if not os.path.exists(fp):\n",
    "#             print('{} doesnt exist'.format(fp))\n",
    "            to_run.append(dict_)\n",
    "    return [tuple(x.values()) for x in to_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = find_which_to_run()\n",
    "to_run = [x for x in to_run if os.path.exists('/home/Public/trondheim/derivatives/bids/sub-{}/ses-{}/func/sub-{}_ses-{}_task-{}_run-{}_bold.nii.gz'.format(x[0], x[1], x[0],x[1], x[2], x[3]))]\n",
    "\n",
    "# to_run = find_all_to_run(True)\n",
    "# to_run = [x for x in to_run if os.path.exists('/home/Public/trondheim/derivatives/bids/sub-{}/ses-{}/func/sub-{}_ses-{}_task-{}_run-{}_bold.nii.gz'.format(x[0], x[1], x[0],x[1], x[2], x[3]))]\n",
    "print(to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_run = [('006', 'mrlc', 'mt', '1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mp_func(tuple_):\n",
    "    subprocess.run(['matlab', '-nodesktop', '-nosplash', '-r ' + prep_matlab_args(*tuple_)])\n",
    "\n",
    "# multiprocess\n",
    "with mp.Pool(8) as p:\n",
    "    p.map(mp_func, to_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if there's still runs found that could be run, these are probably errors!\n",
    "find_which_to_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How large is the influence of each component?\n",
    "2. Fit GLM, get F-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '002'\n",
    "ses = 'anatomical'\n",
    "task = 'rs'\n",
    "run = 1\n",
    "func_fn = f'../derivatives/high_passed_func/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_space-T1w_desc-preproc_bold.nii.gz'\n",
    "brain_mask = func_fn.replace('_desc-preproc_bold.nii.gz', '_desc-brain_mask.nii.gz').replace('high_passed_func', 'fmriprep/fmriprep')\n",
    "\n",
    "# load confounds, name columns\n",
    "confounds = pd.read_csv(f'../derivatives/retroicor_28_regressors/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-retroicor_regressors.tsv', sep='\\t', header=None)\n",
    "confounds = confounds.iloc[:,:28]\n",
    "confounds\n",
    "\n",
    "if confounds.shape[-1] > 20:\n",
    "    hrv_names = ['HRV_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "    rvt_names = ['RVT_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "else:\n",
    "    hrv_names = ['HRV']\n",
    "    rvt_names = ['RVT']\n",
    "\n",
    "confounds.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + hrv_names + rvt_names\n",
    "\n",
    "plt.plot(confounds['HRV_delay_0s'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.design_matrix import _cosine_drift\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "def make_cosine_matrix(func, high_pass=0.01, slice_time_ref=0.5):\n",
    "    t_r = func.header['pixdim'][4]\n",
    "    n_scans = func.header['dim'][4]\n",
    "    start_time = slice_time_ref * t_r\n",
    "    end_time = (n_scans - 1 + slice_time_ref) * t_r\n",
    "    frame_times = np.linspace(start_time, end_time, n_scans)\n",
    "    \n",
    "    cosines = pd.DataFrame(_cosine_drift(0.01, frame_times))\n",
    "    cosines.columns = ['cosine_'+str(x) if (x < cosines.shape[1]-1) else 'intercept' for x in cosines.columns]\n",
    "    return cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def fit_physiology_glms(sub, ses, task, run, fwhm=4.5, models=['retroicor', 'cardiac', 'respiratory', 'interaction', 'hrv', 'rvt'], \n",
    "                        save_models=False, save_dir='../derivatives/glm_nilearn_retroicor/subject_level_models'):\n",
    "    func_fn = f'../derivatives/high_passed_func/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_space-T1w_desc-preproc_bold.nii.gz'\n",
    "    brain_mask = func_fn.replace('_desc-preproc_bold.nii.gz', '_desc-brain_mask.nii.gz').replace('high_passed_func', 'fmriprep/fmriprep')\n",
    "\n",
    "    fwhm_str = str(fwhm).replace('.', 'p')\n",
    "    \n",
    "    # load confounds, name columns\n",
    "    confounds = pd.read_csv(f'../derivatives/retroicor/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-retroicor_regressors.tsv', sep='\\t', header=None)\n",
    "    if confounds.shape[-1] > 25:      # at some point I added delays for the HRV and RVT regressors, but got rid of that again\n",
    "        confounds = confounds.iloc[:,:28]\n",
    "    else:\n",
    "        confounds = confounds.iloc[:,:20]\n",
    "\n",
    "    if confounds.shape[-1] > 20:\n",
    "        hrv_names = ['HRV_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "        rvt_names = ['RVT_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "    else:\n",
    "        hrv_names = ['HRV_delay_0s']\n",
    "        rvt_names = ['RVT_delay_0s']\n",
    "    \n",
    "    confounds.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + hrv_names + rvt_names\n",
    "    \n",
    "#     # We're gonna fit 9 GLMs with increasing physiological |model complexity\n",
    "    if isinstance(models, str):\n",
    "        models = [models]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        \n",
    "        if model == 'retroicor':\n",
    "            dm = confounds[[x for x in confounds.columns if 'cardiac' in x or 'respiratory' in x]]\n",
    "            vmax = .80\n",
    "        elif model == 'cardiac':\n",
    "            dm = confounds[[x for x in confounds.columns if 'cardiac_' in x and not 'respiratory' in x]]\n",
    "            vmax = .80\n",
    "        elif model == 'respiratory':\n",
    "            dm = confounds[[x for x in confounds.columns if 'respiratory_' in x and not 'cardiac' in x]]\n",
    "            vmax = .80\n",
    "        elif model == 'interaction':\n",
    "            dm = confounds[[x for x in confounds.columns if 'respiratoryxcardiac_' in x]]\n",
    "            vmax = .5\n",
    "        elif model == 'hrv':\n",
    "            dm = confounds[['HRV_delay_0s']]\n",
    "            vmax = 0.15\n",
    "        elif model == 'hrv+delays':\n",
    "            dm = confounds[[x for x in confounds.columns if 'HRV_' in x]]\n",
    "        elif model == 'rvt':\n",
    "            vmax = 0.15\n",
    "            dm = confounds[['RVT_delay_0s']]\n",
    "        elif model == 'rvt+delays':\n",
    "            vmax = 0.1\n",
    "            dm = confounds[[x for x in confounds.columns if 'RVT_' in x]]\n",
    "        elif model == 'retroicor+hrv':\n",
    "            vmax = 0.9\n",
    "            dm = confounds[[x for x in confounds.columns if 'cardiac' in x or 'respiratory' in x or x == 'HRV_delay_0s']]\n",
    "        elif model == 'retroicor+rvt':\n",
    "            vmax = 0.9\n",
    "            dm = confounds[[x for x in confounds.columns if 'cardiac' in x or 'respiratory' in x or x == 'RVT_delay_0s']]\n",
    "        elif model == 'retroicor+hrv+rvt':\n",
    "            vmax = 0.9\n",
    "            dm = confounds[[x for x in confounds.columns if 'cardiac' in x or 'respiratory' in x or x == 'HRV_delay_0s' or x == 'RVT_delay_0s']]\n",
    "        elif model == 'retroicor+hrv+rvt+delays':\n",
    "            vmax = 0.9\n",
    "            dm = confounds\n",
    "            \n",
    "        print(dm.shape)\n",
    "        \n",
    "        # z-score, make sure all regressors are mean 0 (except intercept)\n",
    "        dm = dm.apply(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "        # add intercept\n",
    "        dm['intercept'] = 1\n",
    "\n",
    "        # check for existence of final output file name\n",
    "        save_fn2 = os.path.join(save_dir, f'sub-{sub}', f'sub-{sub}_ses-{ses}_task-{task}_run-{run}_model-{model}_fwhm-{fwhm_str}_space-T1w_tsnr_pred_ols.nii.gz')\n",
    "        if os.path.exists(save_fn2):\n",
    "            continue\n",
    "\n",
    "        # fit\n",
    "        flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, smoothing_fwhm=fwhm, noise_model='ols',  # use OLS for tSNR estimations\n",
    "                              mask_img=brain_mask, n_jobs=10, minimize_memory=False,\n",
    "                              signal_scaling=False)                                   # don't scale, we need tSNR estimates\n",
    "        flm_fitted = flm.fit(func_fn, design_matrices=dm)\n",
    "\n",
    "        # Get the following statistics: R-squared, predicted time series, residuals\n",
    "        # tSNR: Get residuals for std, get predicted values for mean\n",
    "        r2_nii = flm_fitted.r_square[0]\n",
    "        \n",
    "        residuals_ = flm_fitted.residuals[0]\n",
    "        predicted_ = flm_fitted.predicted[0]\n",
    "        \n",
    "        predicted_mean = nilearn.image.math_img('nii.mean(-1)', nii=predicted_)\n",
    "        res_std = nilearn.image.math_img('nii.std(-1)', nii=residuals_)\n",
    "        tsnr_pred = nilearn.image.math_img('nii1/nii2', nii1=predicted_mean, nii2=res_std)\n",
    "        \n",
    "        for (spm_name, spm) in zip(['rsquared', 'pred_mean', 'std', 'tsnr_pred'], \n",
    "                                    [r2_nii, predicted_mean, res_std, tsnr_pred]):\n",
    "            save_fn2 = os.path.join(save_dir, f'sub-{sub}', f'sub-{sub}_ses-{ses}_task-{task}_run-{run}_model-{model}_fwhm-{fwhm_str}_space-T1w_{spm_name}_ols.nii.gz')\n",
    "            dirname = os.path.dirname(save_fn2)\n",
    "            if not os.path.exists(dirname):\n",
    "                os.makedirs(dirname)\n",
    "            spm.to_filename(save_fn2)\n",
    "            \n",
    "            # warp\n",
    "            spm_in_mni_fn = apply_warp(spm, sub=sub)\n",
    "            save_fn3 = save_fn2.replace('T1w', 'MNI152NLin2009cAsym')\n",
    "            os.rename(spm_in_mni_fn, save_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = [x.split('/')[-2] for x in sorted(glob.glob('../derivatives/retroicor/*/ses-anatomical'))]\n",
    "all_subs = [x.split('-')[-1] for x in all_subs]\n",
    "# all_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(all_subs, ['anatomical'], ['rs'], [1, 2], [0, 1.5, 6], ['retroicor', 'cardiac', 'respiratory', 'interaction', 'hrv', 'rvt', 'retroicor+hrv+rvt']))\n",
    "# all_combs\n",
    "\n",
    "def fit_physiology_glms_catch(sub, ses, task, run, fwhm, model):\n",
    "    try:\n",
    "        fit_physiology_glms(sub, ses, task, run, fwhm, model)\n",
    "    except:\n",
    "        return '{} {} {} {} {} {} FAILED'.format(sub,ses,task,run,fwhm, model)\n",
    "\n",
    "Parallel(n_jobs=15, verbose=1)(delayed(fit_physiology_glms_catch)(sub, ses, task, run, fwhm, model) for sub, ses, task, run, fwhm, model in all_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit retroicor+HRV+RVT+cosines on non-high-passed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level.design_matrix import _cosine_drift\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "def make_cosine_matrix(func, high_pass=0.01, slice_time_ref=0.5):\n",
    "    t_r = func.header['pixdim'][4]\n",
    "    n_scans = func.header['dim'][4]\n",
    "    start_time = slice_time_ref * t_r\n",
    "    end_time = (n_scans - 1 + slice_time_ref) * t_r\n",
    "    frame_times = np.linspace(start_time, end_time, n_scans)\n",
    "    \n",
    "    cosines = pd.DataFrame(_cosine_drift(0.01, frame_times))\n",
    "    cosines.columns = ['cosine_'+str(x) if (x < cosines.shape[1]-1) else 'intercept' for x in cosines.columns]\n",
    "    return cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def fit_physiology_glms_cosines(sub, ses, task, run, fwhm=4.5):\n",
    "    func_fn = f'../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_space-T1w_desc-preproc_bold.nii.gz'\n",
    "    brain_mask = func_fn.replace('_desc-preproc_bold.nii.gz', '_desc-brain_mask.nii.gz')#.replace('high_passed_func', 'fmriprep/fmriprep')\n",
    "\n",
    "    fwhm_str = str(fwhm).replace('.', 'p')\n",
    "    \n",
    "    # load confounds, name columns\n",
    "    confounds_fn = f'../derivatives/retroicor/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_desc-retroicor_regressors.tsv'\n",
    "    # check fn\n",
    "    if not os.path.exists(confounds_fn):\n",
    "        return 0\n",
    "    \n",
    "    confounds = pd.read_csv(confounds_fn, sep='\\t', header=None)\n",
    "    if confounds.shape[-1] > 25:      # at some point I added delays for the HRV and RVT regressors, but got rid of that again\n",
    "        confounds = confounds.iloc[:,:28]\n",
    "    else:\n",
    "        confounds = confounds.iloc[:,:20]\n",
    "\n",
    "    if confounds.shape[-1] > 20:\n",
    "        hrv_names = ['HRV_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "        rvt_names = ['RVT_delay_' + str(x) + 's' for x in np.arange(0,21,5)]\n",
    "    else:\n",
    "        hrv_names = ['HRV_delay_0s']\n",
    "        rvt_names = ['RVT_delay_0s']\n",
    "    \n",
    "    confounds.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + hrv_names + rvt_names\n",
    "    confounds = confounds[[x for x in confounds.columns if 'cardiac' in x or 'respiratory' in x or x == 'HRV_delay_0s' or x == 'RVT_delay_0s']]\n",
    "    \n",
    "    # add cosines\n",
    "    confounds = pd.concat([confounds, make_cosine_matrix(nib.load(func_fn))], axis=1)\n",
    "    \n",
    "    # check for existence of final output file name\n",
    "    model = 'retroicor+hrv+rvt+cosines'\n",
    "    save_fn2 = f'../derivatives/glm_nilearn_retroicor/subject_level_models3/sub-{sub}_ses-{ses}_task-{task}_run-{run}_model-{model}_fwhm-{fwhm_str}_space-T1w_tsnr_pred_ols.nii.gz'\n",
    "    if os.path.exists(save_fn2):\n",
    "        return 0\n",
    "\n",
    "    # fit\n",
    "    flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, smoothing_fwhm=fwhm, noise_model='ols',  # use OLS for tSNR estimations\n",
    "                          mask_img=brain_mask, n_jobs=1, minimize_memory=False,\n",
    "                          signal_scaling=False)                                   # don't scale, we need tSNR estimates\n",
    "    flm_fitted = flm.fit(func_fn, design_matrices=confounds)\n",
    "\n",
    "    # Get the following statistics: R-squared, predicted time series, residuals\n",
    "    # tSNR: Get residuals for std, get predicted values for mean\n",
    "    r2_nii = flm_fitted.r_square[0]\n",
    "\n",
    "    residuals_ = flm_fitted.residuals[0]\n",
    "    predicted_ = flm_fitted.predicted[0]\n",
    "\n",
    "    predicted_mean = nilearn.image.math_img('nii.mean(-1)', nii=predicted_)\n",
    "    res_std = nilearn.image.math_img('nii.std(-1)', nii=residuals_)\n",
    "    tsnr_pred = nilearn.image.math_img('nii1/nii2', nii1=predicted_mean, nii2=res_std)\n",
    "\n",
    "    for (spm_name, spm) in zip(['rsquared', 'pred_mean', 'std', 'tsnr_pred'], \n",
    "                                [r2_nii, predicted_mean, res_std, tsnr_pred]):\n",
    "        save_fn2 = f'../derivatives/glm_nilearn_retroicor/subject_level_models3/sub-{sub}_ses-{ses}_task-{task}_run-{run}_model-{model}_fwhm-{fwhm_str}_space-T1w_{spm_name}_ols.nii.gz'\n",
    "        spm.to_filename(save_fn2)\n",
    "\n",
    "        # warp\n",
    "        spm_in_mni_fn = apply_warp(spm, sub=sub)\n",
    "        save_fn3 = save_fn2.replace('T1w', 'MNI152NLin2009cAsym')\n",
    "        os.rename(spm_in_mni_fn, save_fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = [x.split('/')[-2] for x in sorted(glob.glob('../derivatives/retroicor/*/ses-anatomical'))]\n",
    "all_subs = [x.split('-')[-1] for x in all_subs]\n",
    "# all_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(all_subs, ['anatomical'], ['rs'], [1, 2], [0]))\n",
    "# all_combs\n",
    "\n",
    "def fit_physiology_glms_cosines_catch(sub, ses, task, run, fwhm):\n",
    "    try:\n",
    "        fit_physiology_glms_cosines(sub, ses, task, run, fwhm)\n",
    "    except:\n",
    "        return '{} {} {} {} {} {} FAILED'.format(sub,ses,task,run,fwhm)\n",
    "\n",
    "Parallel(n_jobs=15, verbose=1)(delayed(fit_physiology_glms_cosines_catch)(sub, ses, task, run, fwhm) for sub, ses, task, run, fwhm in all_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old retroicor GLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit glm and save to disk\n",
    "def make_first_level_model_fn(sub, ses, task, smoothing_fwhm=0, model_n='0', space='T1w', save_dir_name='../derivatives/glm_nilearn_retroicor/subject_level_model'):\n",
    "    smoothing_fwhm = str(smoothing_fwhm).replace('.', 'p')\n",
    "    return os.path.join(save_dir_name, f'sub-{sub}/ses-{ses}/func/fwhm-{smoothing_fwhm}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-first-level-model.pkl')\n",
    "\n",
    "\n",
    "def fit_retroicor_glm(sub, ses, task, return_glm=False):\n",
    "    \n",
    "    save_fn = make_first_level_model_fn(sub, ses, task, smoothing_fwhm=0, model_n='0', space='T1w', save_dir_name='../derivatives/glm_nilearn_retroicor/subject_level_model') # f'../derivatives/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{smoothing_fwhm_str}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-first-level-model.pkl'\n",
    "\n",
    "    funcs = []\n",
    "    dms = []\n",
    "    func_fns = sorted(glob.glob('../derivatives/high_passed_func/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_space-T1w_desc-preproc_bold.nii.gz'.format(sub=sub, ses=ses, task=task)))\n",
    "    for run, func_fn in enumerate(func_fns):\n",
    "        retroicor_fn = func_fn.replace('high_passed_func', 'retroicor').replace('_space-T1w_desc-preproc_bold.nii.gz', '_desc-retroicor_regressors.tsv')\n",
    "\n",
    "        ## load func\n",
    "        func = nib.load(func_fn)\n",
    "        retroicor = pd.read_csv(retroicor_fn, sep='\\t', header=None).iloc[:,:20]  ## 20 components in total\n",
    "        retroicor.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + ['HRV', 'RVT']\n",
    "\n",
    "#         # add cosines  # nope, let's use the high-passed data so we can get a R^2 estimate for the physiological noise only\n",
    "#         design_matrix = pd.concat([retroicor, make_cosine_matrix(func)], 1)\n",
    "        retroicor['intercept'] = 1    \n",
    "        design_matrix = retroicor\n",
    "#         plot_design_matrix(design_matrix)\n",
    "        funcs.append(func)\n",
    "        dms.append(design_matrix)\n",
    "    \n",
    "    brain_mask = func_fns[0].replace('_desc-preproc_bold.nii.gz', '_desc-brain_mask.nii.gz').replace('high_passed_func', 'fmriprep/fmriprep')\n",
    "    print('Fitting GLM for sub {} ses {} task {} ({} runs)...'.format(sub, ses, task, len(func_fns)), end='')\n",
    "    \n",
    "    # NB; minimize_memory=False saves the model per voxel so we can get R2 estimates to plot\n",
    "    flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, smoothing_fwhm=1.5, mask_img=brain_mask, n_jobs=10)\n",
    "    flm_fitted = flm.fit(funcs, design_matrices=dms)\n",
    "        \n",
    "    # save\n",
    "    os.makedirs(os.path.dirname(save_fn), exist_ok=True)\n",
    "    with open(save_fn, 'wb') as f:\n",
    "        pkl.dump(flm_fitted, f, protocol=4)  # protocol=4 required due to size of pkl\n",
    "\n",
    "    return flm_fitted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_to_run(return_tuple=False):\n",
    "    # if you want to run everything...\n",
    "    all_retroicor_regressors = sorted(glob.glob('../derivatives/retroicor/sub-*/ses-*/func/*retroicor_regressors.tsv'))\n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-.*_desc-retroicor_regressors.tsv')\n",
    "    all_retroicor_regressors_dict = [regex.match(x).groupdict() for x in all_retroicor_regressors]\n",
    "    all_retroicor_regressors_df = pd.DataFrame.from_dict(all_retroicor_regressors_dict).sort_values(['sub','ses','task']).drop_duplicates()\n",
    "    \n",
    "    dict_list = all_retroicor_regressors_df.to_dict(orient='records')\n",
    "    if return_tuple:\n",
    "        return [tuple(x.values()) for x in dict_list]\n",
    "    else:\n",
    "        return dict_list\n",
    "\n",
    "def find_which_to_run():\n",
    "    # finds all runs for which there are RETROICOR regressors, and removes those for which there's an output already\n",
    "    # ie returns the tuples corresponding to subjects for which fit_retroicor_glm hasn't been run yet\n",
    "    all_retroicor_regressors = find_all_to_run()\n",
    "    \n",
    "    to_run = []\n",
    "    for dict_ in all_retroicor_regressors:\n",
    "        fp = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-retroicor_glm_SPMs.pdf'.format(**dict_)\n",
    "        if not os.path.exists(fp):\n",
    "#             print('{} doesnt exist'.format(fp))\n",
    "            to_run.append(dict_)\n",
    "    return [tuple(x.values()) for x in to_run]\n",
    "\n",
    "# find_which_to_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = find_all_to_run(True)\n",
    "to_run = [(x[0], x[1], x[2]) for x in to_run if x[1] == 'anatomical']\n",
    "to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_retroicor_glm('002', 'anatomical', 'rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_run = find_all_to_run(True)\n",
    "\n",
    "# to_run = [('002', 'anatomical', 'rs'),\n",
    "#  ('003', 'rlsat', 'rlsat'),\n",
    "#  ('005', 'sstmsit', 'msit'),\n",
    "#  ('005', 'sstmsit', 'sst'),\n",
    "# # ('007', 'rlsat', 'rlsat'),\n",
    "#  ('009', 'anatomical', 'rs'),\n",
    "#  ('009', 'sstmsit', 'msit'),\n",
    "#  ('009', 'sstmsit', 'sst'),\n",
    "#  ('010', 'anatomical', 'rs'),\n",
    "#  ('011', 'anatomical', 'rs'),\n",
    "#  ('011', 'rlsat', 'rlsat')]\n",
    "\n",
    "# print(to_run)\n",
    "\n",
    "# beware memory load\n",
    "#Parallel(n_jobs=8, verbose=1)(delayed(fit_retroicor_glm)(sub, ses, task) for sub, ses, task in to_run)\n",
    "\n",
    "def fit_retroicor_glm_catch(sub,ses,task):\n",
    "    try:\n",
    "        fit_retroicor_glm(sub,ses,task)\n",
    "    except:\n",
    "        print('{} {} {} FAILED'.format(sub,ses,task))\n",
    "        return 1\n",
    "\n",
    "## with catch\n",
    "Parallel(n_jobs=5, verbose=1)(delayed(fit_retroicor_glm_catch)(sub, ses, task) for sub, ses, task in to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute first-level contrasts, warp to MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrasts(comb, contrasts, space='T1w', save_dir_name='../derivatives/glm_nilearn_retroicor/subject_level_model'):\n",
    "    sub,ses,task = comb\n",
    "    \n",
    "    flm_fn = f'../derivatives/glm_nilearn_retroicor/subject_level_model/sub-{sub}/ses-{ses}/func/fwhm-0/sub-{sub}_ses-{ses}_task-{task}_space-T1w_desc-first-level-model.pkl'\n",
    "    with open(flm_fn, 'rb') as f:\n",
    "        first_level_model = pkl.load(f)\n",
    "    \n",
    "    for contrast_name, contrast in contrasts.items():\n",
    "        \n",
    "        # save all stat maps\n",
    "        stat_maps = first_level_model.compute_contrast(contrast, output_type='all')\n",
    "        for stat_map_name, stat_map in stat_maps.items():\n",
    "#             if not stat_map_name in ['z_score', 'effect_size', 'effect_variance']:\n",
    "#                 continue  # drop p-value and 'stat'\n",
    "            save_fn = flm_fn.replace('desc-first-level-model.pkl', f'desc-contrast-{contrast_name}_{stat_map_name}.nii.gz')\n",
    "            stat_map.to_filename(save_fn)\n",
    "            \n",
    "            # warp\n",
    "            stat_map_warped = apply_warp(save_fn, sub)            \n",
    "            # move\n",
    "            os.rename(stat_map_warped, save_fn.replace('space-T1w', 'space-MNI152NLin2009cAsym'))\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "# Which contrasts are we interested in?\n",
    "dm = flms[0].design_matrices_[0]\n",
    "simple_contrasts = np.eye(dm.shape[1])\n",
    "contrasts = {'cardiac': simple_contrasts[:6,:],\n",
    "             'respiratory': simple_contrasts[6:(6+8),:],\n",
    "             'interaction': simple_contrasts[(6+8):(6+8+4),:],\n",
    "             'RETROICOR': simple_contrasts[:(6+8+4),:],\n",
    "             'HRV': simple_contrasts[18,:],\n",
    "             'RVT': simple_contrasts[19,:],\n",
    "             }\n",
    "\n",
    "# Multiprocess\n",
    "def compute_contrasts_catch(comb, contrasts):\n",
    "    try:\n",
    "        compute_contrasts(comb, contrasts)\n",
    "    except:\n",
    "        print('{} {} {} FAILED'.format(sub,ses,task))\n",
    "        return 1\n",
    "\n",
    "\n",
    "Parallel(n_jobs=20, verbose=1)(delayed(compute_contrasts_catch)( (sub, ses, task), contrasts=contrasts ) for sub, ses, task in to_run)\n",
    "\n",
    "#compute_contrasts(to_run[0], contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slm = nilearn.glm.second_level.SecondLevelModel()\n",
    "# slm = slm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fwhm = 1.5\n",
    "#fwhm_str = str(fwhm).replace('.', 'p')\n",
    "#model_n = 0\n",
    "\n",
    "#contrast_name = 'SPD-ACC'\n",
    "imgs = sorted(glob.glob(f'../derivatives/glm_nilearn_retroicor/subject_level_model/sub-*/ses-anatomical/func/fwhm-*/*MNI*desc-contrast-*_effect_size*'))\n",
    "regex = re.compile('.*/sub-(?P<sub>\\d+)/.*/fwhm-(?P<fwhm>\\S+)/sub-.*_desc-contrast-(?P<contrast_name>\\S+)_effect_size.nii.gz')\n",
    "\n",
    "df = pd.DataFrame({'effects_map_path':imgs})\n",
    "df['subject_label'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['sub'])\n",
    "df['fwhm'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['fwhm'])\n",
    "#df['model_n'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['model_n'])\n",
    "df['map_name'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['contrast_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_second_level_model(first_level_contrast, df, fwhm=None):\n",
    "    df_in = df.loc[(df.map_name==first_level_contrast) & (df.fwhm==str(0).replace('.', 'p'))].copy()\n",
    "    dm_in = df_in.copy()\n",
    "    dm_in['intercept'] = 1\n",
    "    dm_in = dm_in[['intercept']].reset_index(drop=True)\n",
    "\n",
    "    slm = nilearn.glm.second_level.SecondLevelModel(n_jobs=20, smoothing_fwhm=fwhm)\n",
    "    slm = slm.fit(df_in.effects_map_path.values.tolist(), design_matrix=dm_in)\n",
    "    return slm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(6,1, figsize=(10,40))\n",
    "for i, contrast_name in enumerate(['cardiac', 'respiratory', 'interaction', 'RETROICOR', 'HRV', 'RVT']):\n",
    "    slm = fit_second_level_model(contrast_name, df)\n",
    "    z_map = slm.compute_contrast('intercept', output_type='z_score')\n",
    "    plotting.plot_stat_map(z_map, axes=ax[i], title=contrast_name)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With 4.5 mm smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(6,1, figsize=(10,40))\n",
    "for i, contrast_name in enumerate(['cardiac', 'respiratory', 'interaction', 'RETROICOR', 'HRV', 'RVT']):\n",
    "    slm = fit_second_level_model(contrast_name, df, fwhm=4.5)\n",
    "    z_map = slm.compute_contrast('intercept', output_type='z_score')\n",
    "    plotting.plot_stat_map(z_map, axes=ax[i], title=contrast_name)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del flms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_retroicor = fit_second_level_model('RETROICOR', df)\n",
    "z_map_retroicor = slm_retroicor.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_retroicor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_cardiac = fit_second_level_model('cardiac', df)\n",
    "z_map_cardiac = slm_cardiac.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_cardiac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_respiratory = fit_second_level_model('respiratory', df)\n",
    "z_map_respiratory = slm_respiratory.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_respiratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_interaction = fit_second_level_model('interaction', df)\n",
    "z_map_interaction = slm_interaction.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_HRV = fit_second_level_model('HRV', df)\n",
    "z_map_HRV = slm_HRV.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_HRV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slm_RVT = fit_second_level_model('RVT', df)\n",
    "z_map_RVT = slm_RVT.compute_contrast('intercept', output_type='z_score')\n",
    "plotting.plot_stat_map(z_map_RVT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_second_level_spm(spm, first_level_contrast_name, second_level_contrast_name, fwhm, save_dir_name='../derivatives/glm_nilearn_retroicor/group_level_model/ses-anatomical'):\n",
    "    fwhm = str(fwhm).replace('.', 'p')\n",
    "    save_fn = os.path.join(save_dir_name, f'fwhm-{fwhm}/firstlevelcontrast-{first_level_contrast_name}_secondlevelcontrast-{second_level_contrast_name}.nii.gz')\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(save_fn)):\n",
    "        os.makedirs(os.path.dirname(save_fn))\n",
    "    \n",
    "    spm.to_filename(save_fn)\n",
    "    nilearn.image.math_img('-nii', nii=spm).to_filename(save_fn.replace('.nii.gz', '-neg.nii.gz'))\n",
    "    \n",
    "def fit_second_level_models(first_level_contrast, second_level_contrast, fwhm, df):\n",
    "    print(f'{fwhm} {model_n} {first_level_contrast}')\n",
    "    dm = df.loc[(df.map_name==first_level_contrast) & (df.fwhm==str(fwhm).replace('.', 'p'))].copy()\n",
    "    #dm = pd.merge(df_in, parameters[['subject_label', 'B0.SPD-ACC_z']]) #, 'V0.SPD-ACC_z']])\n",
    "    dm['intercept'] = 1\n",
    "\n",
    "#     if first_level_contrast == 'SPD-ACC':\n",
    "#         dm_in = dm[['intercept', 'B0.SPD-ACC_z']] #, 'V0.SPD-ACC_z']]\n",
    "#     else:\n",
    "    dm_in = dm[['intercept']]\n",
    "    \n",
    "    slm = SecondLevelModel()\n",
    "    slm_fitted = slm.fit(second_level_input=df_in.effects_map_path.values.tolist(), design_matrix=dm_in)\n",
    "\n",
    "    # Intercept, threshold covariance, urgency covariance\n",
    "    cmap = slm_fitted.compute_contrast('intercept', output_type='z_score')\n",
    "    save_second_level_spm(cmap, first_level_contrast_name=first_level_contrast, second_level_contrast_name=second_level_contrast, fwhm=fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.map_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(df.map_name.unique().tolist(), ['intercept'], [0]))\n",
    "all_combs\n",
    "\n",
    "_ = joblib.Parallel(n_jobs=10, verbose=1)(joblib.delayed(fit_second_level_models)(first_level_contrast, second_level_contrast, fwhm, df=df) for first_level_contrast,second_level_contrast,fwhm in all_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = slm.compute_contrast(first_level_contrast=contrasts['cardiac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_retroicor_glm(sub, ses, task, return_glm=False):\n",
    "    funcs = []\n",
    "    dms = []\n",
    "    func_fns = sorted(glob.glob('../derivatives/high_passed_func/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_space-T1w_desc-preproc_bold.nii.gz'.format(sub=sub, ses=ses, task=task)))\n",
    "    for run, func_fn in enumerate(func_fns):\n",
    "        retroicor_fn = func_fn.replace('high_passed_func', 'retroicor').replace('_space-T1w_desc-preproc_bold.nii.gz', '_desc-retroicor_regressors.tsv')\n",
    "\n",
    "        ## load func\n",
    "        func = nib.load(func_fn)\n",
    "        retroicor = pd.read_csv(retroicor_fn, sep='\\t', header=None).iloc[:,:20]  ## 20 components in total\n",
    "        retroicor.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + ['HRV', 'RVT']\n",
    "\n",
    "#         # add cosines  # nope, let's use the high-passed data so we can get a R^2 estimate for the physiological noise only\n",
    "#         design_matrix = pd.concat([retroicor, make_cosine_matrix(func)], 1)\n",
    "        retroicor['intercept'] = 1    \n",
    "        design_matrix = retroicor\n",
    "#         plot_design_matrix(design_matrix)\n",
    "        funcs.append(func)\n",
    "        dms.append(design_matrix)\n",
    "    \n",
    "    brain_mask = func_fns[0].replace('_desc-preproc_bold.nii.gz', '_desc-brain_mask.nii.gz').replace('high_passed_func', 'fmriprep/fmriprep')\n",
    "    print('Fitting GLM for sub {} ses {} task {} ({} runs)...'.format(sub, ses, task, len(func_fns)), end='')\n",
    "    \n",
    "    # NB; minimize_memory=False saves the model per voxel so we can get R2 estimates to plot\n",
    "    flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, smoothing_fwhm=4.5, mask_img=brain_mask, n_jobs=10, minimize_memory=False)    # lekker smoothen\n",
    "    flm_fitted = flm.fit(funcs, design_matrices=dms)\n",
    "\n",
    "    # define & plot contrasts\n",
    "    simple_contrasts = np.eye(dms[0].shape[1])\n",
    "    contrasts = {'cardiac': simple_contrasts[:6,:],\n",
    "                 'respiratory': simple_contrasts[6:(6+8),:],\n",
    "                 'interaction': simple_contrasts[(6+8):(6+8+4),:],\n",
    "                 'HRV': simple_contrasts[18,:],\n",
    "                 'RVT': simple_contrasts[19,:],\n",
    "                 }\n",
    "\n",
    "    print('plotting...')\n",
    "    vmaxes = {'cardiac': 37, 'respiratory': 30, 'interaction': 15, 'HRV': 10, 'RVT': 8}\n",
    "    templ = '../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii'\n",
    "\n",
    "    f, ax = plt.subplots(6,3, figsize=(12,15), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "    for i, (contrast_name, c_) in enumerate(contrasts.items()):\n",
    "        z_map_ftest = flm_fitted.compute_contrast(\n",
    "                               c_,\n",
    "                               stat_type='F',\n",
    "                               output_type='z_score')\n",
    "        vmax = vmaxes[contrast_name]\n",
    "        \n",
    "        # warp to MNI\n",
    "        z_map_ftest = apply_warp(z_map_ftest, sub=sub)\n",
    "        \n",
    "        plotting.plot_stat_map(z_map_ftest, bg_img=nib.load(templ), vmax=vmax, title=contrast_name, display_mode='x', cut_coords=[3], axes=ax[i,0], colorbar=False)\n",
    "        plotting.plot_stat_map(z_map_ftest, bg_img=nib.load(templ), vmax=vmax, display_mode='y', cut_coords=[-3], axes=ax[i,1], colorbar=False)\n",
    "        plotting.plot_stat_map(z_map_ftest, bg_img=nib.load(templ), vmax=vmax, display_mode='z', cut_coords=[15], axes=ax[i,2])\n",
    "        os.remove(z_map_ftest) # cleanup\n",
    "    \n",
    "    # plot\n",
    "    r2_nii = flm_fitted.r_square[0]\n",
    "    r2_nii = apply_warp(r2_nii, sub=sub) # warp to MNI\n",
    "    plotting.plot_stat_map(r2_nii, bg_img=nib.load(templ), vmax=0.6, title='R^2', display_mode='x', cut_coords=[3], axes=ax[-1,0], colorbar=False)\n",
    "    plotting.plot_stat_map(r2_nii, bg_img=nib.load(templ), vmax=0.6, display_mode='y', cut_coords=[-3], axes=ax[-1,1], colorbar=False)\n",
    "    plotting.plot_stat_map(r2_nii, bg_img=nib.load(templ), vmax=0.6, display_mode='z', cut_coords=[15], axes=ax[-1,2])\n",
    "    os.remove(r2_nii) # cleanup\n",
    "    \n",
    "    plot_fn = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-retroicor_glm_SPMs.pdf'.format(sub=sub, ses=ses, task=task)\n",
    "    os.makedirs(os.path.dirname(plot_fn), exist_ok=True)\n",
    "#     plot_fn = retroicor_fn.replace('_desc-retroicor_regressors.tsv', '_retroicor-glm.pdf').replace('_run-2', '').replace('_run-1', '').replace('_run-3', '')\n",
    "    f.savefig(plot_fn, bbox_inches='tight')\n",
    "    \n",
    "    if return_glm:\n",
    "        return flm_fitted\n",
    "    else:\n",
    "        del flm_fitted\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_to_run(return_tuple=False):\n",
    "    # if you want to run everything...\n",
    "    all_retroicor_regressors = sorted(glob.glob('../derivatives/retroicor/sub-*/ses-*/func/*retroicor_regressors.tsv'))\n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-.*_desc-retroicor_regressors.tsv')\n",
    "    all_retroicor_regressors_dict = [regex.match(x).groupdict() for x in all_retroicor_regressors]\n",
    "    all_retroicor_regressors_df = pd.DataFrame.from_dict(all_retroicor_regressors_dict).sort_values(['sub','ses','task']).drop_duplicates()\n",
    "    \n",
    "    dict_list = all_retroicor_regressors_df.to_dict(orient='records')\n",
    "    if return_tuple:\n",
    "        return [tuple(x.values()) for x in dict_list]\n",
    "    else:\n",
    "        return dict_list\n",
    "\n",
    "def find_which_to_run():\n",
    "    # finds all runs for which there are RETROICOR regressors, and removes those for which there's an output already\n",
    "    # ie returns the tuples corresponding to subjects for which fit_retroicor_glm hasn't been run yet\n",
    "    all_retroicor_regressors = find_all_to_run()\n",
    "    \n",
    "    to_run = []\n",
    "    for dict_ in all_retroicor_regressors:\n",
    "        fp = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-retroicor_glm_SPMs.pdf'.format(**dict_)\n",
    "        if not os.path.exists(fp):\n",
    "#             print('{} doesnt exist'.format(fp))\n",
    "            to_run.append(dict_)\n",
    "    return [tuple(x.values()) for x in to_run]\n",
    "\n",
    "find_which_to_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = find_which_to_run()\n",
    "#to_run = find_all_to_run(True)\n",
    "\n",
    "# to_run = [('002', 'anatomical', 'rs'),\n",
    "#  ('003', 'rlsat', 'rlsat'),\n",
    "#  ('005', 'sstmsit', 'msit'),\n",
    "#  ('005', 'sstmsit', 'sst'),\n",
    "# # ('007', 'rlsat', 'rlsat'),\n",
    "#  ('009', 'anatomical', 'rs'),\n",
    "#  ('009', 'sstmsit', 'msit'),\n",
    "#  ('009', 'sstmsit', 'sst'),\n",
    "#  ('010', 'anatomical', 'rs'),\n",
    "#  ('011', 'anatomical', 'rs'),\n",
    "#  ('011', 'rlsat', 'rlsat')]\n",
    "\n",
    "# print(to_run)\n",
    "\n",
    "# beware memory load\n",
    "#Parallel(n_jobs=8, verbose=1)(delayed(fit_retroicor_glm)(sub, ses, task) for sub, ses, task in to_run)\n",
    "\n",
    "def fit_retroicor_glm_catch(sub,ses,task):\n",
    "    try:\n",
    "        fit_retroicor_glm(sub,ses,task)\n",
    "    except:\n",
    "        print('{} {} {} FAILED'.format(sub,ses,task))\n",
    "        return 1\n",
    "    \n",
    "## with catch\n",
    "Parallel(n_jobs=5, verbose=1)(delayed(fit_retroicor_glm_catch)(sub, ses, task) for sub, ses, task in to_run)\n",
    "\n",
    "# for sub,ses,task in to_run:\n",
    "#     print(sub,ses,task)\n",
    "#     try:\n",
    "#         fit_retroicor_glm(sub,ses,task)\n",
    "#     except:\n",
    "#         print('FAILED: ')\n",
    "#         print(sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_which_to_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Left > Right motor response (only for non-RS, obviously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_responsehand_glms(glms, sub, x=34, y=-20, z=58):\n",
    "    zs = [x.compute_contrast('response_left - response_right') for x in glms]\n",
    "    \n",
    "    templ = '../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii'\n",
    "\n",
    "    contrast_name = 'left>right'\n",
    "    n_runs = len(zs)\n",
    "    f, ax = plt.subplots(n_runs,3, figsize=(12, n_runs*2), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "    \n",
    "    if n_runs > 1:\n",
    "        for run in range(n_runs-1):\n",
    "            # warp z-map to mni\n",
    "            z_map = zs[run]\n",
    "            z_map = apply_warp(z_map, sub=sub)\n",
    "            \n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), title='Run {}'.format(run+1), display_mode='x', cut_coords=[x], axes=ax[run,0], colorbar=False)\n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='y', cut_coords=[y], axes=ax[run,1], colorbar=False)\n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='z', cut_coords=[z], axes=ax[run,2])\n",
    "            os.remove(z_map) # clean-up\n",
    "    \n",
    "    run = n_runs-1\n",
    "    z_map = zs[run]\n",
    "    z_map = apply_warp(z_map, sub=sub)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), title='Fixed effects across runs', display_mode='x', cut_coords=[x], axes=ax[run,0], colorbar=False)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='y', cut_coords=[y], axes=ax[run,1], colorbar=False)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='z', cut_coords=[z], axes=ax[run,2])\n",
    "    os.remove(z_map)\n",
    "    return f, ax\n",
    "\n",
    "def fit_responsehand_glm(sub, ses, task, include_physio=True, per_run=True, return_glms=False):\n",
    "    event_fns = sorted(glob.glob('../derivatives/event_files/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_events.tsv'.format(sub=sub, ses=ses, task=task)))\n",
    "    run_flms = []\n",
    "    run_events = []\n",
    "    run_funcs = []\n",
    "    run_confounds = []\n",
    "\n",
    "    for run, event_fn in enumerate(event_fns):\n",
    "        run += 1\n",
    "        events = pd.read_csv(event_fn, sep='\\t', index_col=None)\n",
    "        events = events.loc[events.trial_type.isin(['response_left', 'response_right'])] \n",
    "        events['duration'] = 0.001\n",
    "        run_events.append(events)\n",
    "\n",
    "        ## load func\n",
    "        func_fn = '../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_space-T1w_desc-preproc_bold.nii.gz'.format(sub=sub, ses=ses, task=task, run=run)\n",
    "        brain_mask = func_fn.replace('desc-preproc_bold', 'desc-brain_mask')\n",
    "        func = nib.load(func_fn)\n",
    "        run_funcs.append(func)\n",
    "        \n",
    "        if include_physio:\n",
    "            ## load confounds\n",
    "            retroicor_fn = func_fn.replace('fmriprep/fmriprep', 'retroicor').replace('_space-T1w_desc-preproc_bold.nii.gz', '_desc-retroicor_regressors.tsv')\n",
    "            retroicor = pd.read_csv(retroicor_fn, sep='\\t', header=None).iloc[:,:20]  ## 20 components in total\n",
    "            retroicor.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + ['HRV', 'RVT']\n",
    "        else:\n",
    "            retroicor=None\n",
    "        \n",
    "        run_confounds.append(retroicor)\n",
    "        \n",
    "        # fit run-level model\n",
    "        if per_run:\n",
    "            flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, mask_img=brain_mask, smoothing_fwhm=4.5, n_jobs=20)  # lekker smoothen\n",
    "            flm_fitted = flm.fit(func, events=events, confounds=retroicor)\n",
    "            run_flms.append(flm_fitted)\n",
    "        \n",
    "    flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, mask_img=brain_mask, smoothing_fwhm=4.5, n_jobs=20)  # lekker smoothen\n",
    "    flm_fitted = flm.fit(run_funcs, events=run_events, confounds=run_confounds if include_physio else None)\n",
    "    run_flms.append(flm_fitted)\n",
    "    \n",
    "    f, ax = plot_responsehand_glms(run_flms, sub)\n",
    "    plot_fn = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-motor_contrast_glm_SPMs.pdf'.format(sub=sub, ses=ses, task=task)\n",
    "#     plot_fn = event_fns[0].replace('event_files', 'quality_control_plots').replace('_events.tsv', '_desc-motor_contrast.pdf')\n",
    "    os.makedirs(os.path.dirname(plot_fn), exist_ok=True)\n",
    "    f.savefig(plot_fn)\n",
    "    \n",
    "    if return_glms:\n",
    "        return run_flms\n",
    "    else:\n",
    "        del run_flms\n",
    "        return 0\n",
    "    \n",
    "def plot_responsefinger_glms(glms, response_contrast, sub, x=34, y=-20, z=58):\n",
    "    \n",
    "    #for response_contrast in ['response_index - response_middle', 'response_index - response_ring', 'response_ring - response_middle']\n",
    "    \n",
    "    #zs = [x.compute_contrast('response_index - response_middle') for x in glms]\n",
    "    zs = [x.compute_contrast(response_contrast) for x in glms]\n",
    "\n",
    "    templ = '../sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii'\n",
    "\n",
    "    contrast_name = 'index>middle'\n",
    "    n_runs = len(zs)\n",
    "    f, ax = plt.subplots(n_runs,3, figsize=(12, n_runs*2), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "    if n_runs > 1:\n",
    "        for run in range(n_runs-1):\n",
    "            z_map = zs[run]\n",
    "            z_map = apply_warp(z_map, sub=sub)\n",
    "\n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), title='Run {}'.format(run+1), display_mode='x', cut_coords=[x], axes=ax[run,0], colorbar=False)\n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='y', cut_coords=[y], axes=ax[run,1], colorbar=False)\n",
    "            plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='z', cut_coords=[z], axes=ax[run,2])\n",
    "            os.remove(z_map)\n",
    "            \n",
    "    run = n_runs-1\n",
    "    z_map = zs[run]\n",
    "    z_map = apply_warp(z_map, sub=sub)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), title='Fixed effects across runs', display_mode='x', cut_coords=[x], axes=ax[run,0], colorbar=False)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='y', cut_coords=[y], axes=ax[run,1], colorbar=False)\n",
    "    plotting.plot_stat_map(z_map, bg_img=nib.load(templ), display_mode='z', cut_coords=[z], axes=ax[run,2])\n",
    "    os.remove(z_map)\n",
    "    return f, ax\n",
    "\n",
    "def fit_responsefinger_glm(sub, ses, task, include_physio=True, per_run=True, return_glms=False):\n",
    "    \n",
    "    event_fns = sorted(glob.glob('../derivatives/event_files/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_events.tsv'.format(sub=sub, ses=ses, task=task)))\n",
    "    run_flms = []\n",
    "    run_events = []\n",
    "    run_funcs = []\n",
    "    run_confounds = []\n",
    "\n",
    "    for run, event_fn in enumerate(event_fns):\n",
    "        run += 1\n",
    "        events = pd.read_csv(event_fn, sep='\\t', index_col=None)\n",
    "        events = events.loc[events.trial_type.isin(['response_index', 'response_middle','response_ring'])] \n",
    "        events['duration'] = 0.001\n",
    "        run_events.append(events)\n",
    "\n",
    "        ## load func\n",
    "        func_fn = '../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run}_space-T1w_desc-preproc_bold.nii.gz'.format(sub=sub, ses=ses, task=task, run=run)\n",
    "        brain_mask = func_fn.replace('desc-preproc_bold', 'desc-brain_mask')\n",
    "        func = nib.load(func_fn)\n",
    "        run_funcs.append(func)\n",
    "        \n",
    "        if include_physio:\n",
    "            ## load confounds\n",
    "            retroicor_fn = func_fn.replace('fmriprep/fmriprep', 'retroicor').replace('_space-T1w_desc-preproc_bold.nii.gz', '_desc-retroicor_regressors.tsv')\n",
    "            retroicor = pd.read_csv(retroicor_fn, sep='\\t', header=None).iloc[:,:20]  ## 20 components in total\n",
    "            retroicor.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + ['HRV', 'RVT']\n",
    "        else:\n",
    "            retroicor=None\n",
    "        \n",
    "        run_confounds.append(retroicor)\n",
    "        \n",
    "        # fit run-level model\n",
    "        if per_run:\n",
    "            flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, mask_img=brain_mask, smoothing_fwhm=4.5, n_jobs=20)  # lekker smoothen\n",
    "            flm_fitted = flm.fit(func, events=events, confounds=retroicor)\n",
    "            run_flms.append(flm_fitted)\n",
    "        \n",
    "    flm = FirstLevelModel(t_r=1.38, slice_time_ref=0.5, mask_img=brain_mask, smoothing_fwhm=4.5, n_jobs=20)  # lekker smoothen\n",
    "    flm_fitted = flm.fit(run_funcs, events=run_events, confounds=run_confounds if include_physio else None)\n",
    "    run_flms.append(flm_fitted)\n",
    "    \n",
    "    for response_contrast, save_contrast in zip(['response_index - response_middle', 'response_index - response_ring', 'response_ring - response_middle'],['IminM','IminR','RminM']):\n",
    "        f, ax = plot_responsefinger_glms(run_flms, response_contrast, sub)\n",
    "        plot_fn = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-motor_contrast-{save_contrast}_glm_SPMs.pdf'.format(sub=sub, ses=ses, task=task, save_contrast=save_contrast)\n",
    "    #     plot_fn = event_fns[0].replace('event_files', 'quality_control_plots').replace('_events.tsv', '_desc-motor_contrast.pdf')\n",
    "        os.makedirs(os.path.dirname(plot_fn), exist_ok=True)\n",
    "        f.savefig(plot_fn)\n",
    "    \n",
    "    if return_glms:\n",
    "        return run_flms\n",
    "    else:\n",
    "        del run_flms\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-MSIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_to_run_nonmsit(return_tuple=False):\n",
    "    # if you want to run everything...\n",
    "    all_event_files = sorted(glob.glob('../derivatives/event_files/sub-*/ses-*/func/sub-*_ses-*_task-*_run-*_events.tsv'))\n",
    "    all_event_files = [x for x in all_event_files if not 'task-msit' in x]\n",
    "    \n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-.*_events.tsv')\n",
    "    all_event_files_dict = [regex.match(x).groupdict() for x in all_event_files]\n",
    "    all_event_files_df = pd.DataFrame.from_dict(all_event_files_dict).sort_values(['sub','ses','task']).drop_duplicates()\n",
    "    \n",
    "    dict_list = all_event_files_df.to_dict(orient='records')\n",
    "    if return_tuple:\n",
    "        return [tuple(x.values()) for x in dict_list]\n",
    "    else:\n",
    "        return dict_list\n",
    "\n",
    "def find_which_to_run_nonmsit():\n",
    "    # finds all runs for which there are RETROICOR regressors, and removes those for which there's an output already\n",
    "    # ie returns the tuples corresponding to subjects for which fit_retroicor_glm hasn't been run yet\n",
    "    all_event_files = find_all_to_run_nonmsit()\n",
    "    \n",
    "    to_run = []\n",
    "    for dict_ in all_event_files:\n",
    "        fp = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-motor_contrast_glm_SPMs.pdf'.format(**dict_)\n",
    "        if not os.path.exists(fp):\n",
    "#             print('{} doesnt exist'.format(fp))\n",
    "            to_run.append(dict_)\n",
    "    return [tuple(x.values()) for x in to_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = find_all_to_run_nonmsit(True)\n",
    "to_run = find_which_to_run_nonmsit()\n",
    "print(to_run)\n",
    "\n",
    "## joblib, also here careful with n_jobs\n",
    "Parallel(n_jobs=10, verbose=1)(delayed(fit_responsehand_glm)(sub, ses, task) for sub, ses, task in to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_to_run_msit(return_tuple=False):\n",
    "    # if you want to run everything...\n",
    "    all_event_files = sorted(glob.glob('../derivatives/event_files/sub-*/ses-*/func/sub-*_ses-*_task-msit_run-*_events.tsv'))\n",
    "    \n",
    "    regex = re.compile('.*sub-(?P<sub>\\d+)/ses-(?P<ses>\\S+)/func/sub-.*_ses-.*_task-(?P<task>\\S+)_run-.*_events.tsv')\n",
    "    all_event_files_dict = [regex.match(x).groupdict() for x in all_event_files]\n",
    "    all_event_files_df = pd.DataFrame.from_dict(all_event_files_dict).sort_values(['sub','ses','task']).drop_duplicates()\n",
    "    \n",
    "    dict_list = all_event_files_df.to_dict(orient='records')\n",
    "    if return_tuple:\n",
    "        return [tuple(x.values()) for x in dict_list]\n",
    "    else:\n",
    "        return dict_list\n",
    "\n",
    "def find_which_to_run_msit():\n",
    "    # finds all runs for which there are RETROICOR regressors, and removes those for which there's an output already\n",
    "    # ie returns the tuples corresponding to subjects for which fit_retroicor_glm hasn't been run yet\n",
    "    all_event_files = find_all_to_run_msit()\n",
    "    \n",
    "    to_run = []\n",
    "    for dict_ in all_event_files:\n",
    "        fp = '../derivatives/quality_control_plots/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_desc-motor_contrast-IminM_glm_SPMs.pdf'.format(**dict_)\n",
    "        if not os.path.exists(fp):\n",
    "#             print('{} doesnt exist'.format(fp))\n",
    "            to_run.append(dict_)\n",
    "    return [tuple(x.values()) for x in to_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_run = find_all_to_run_msit(True) #[('003', 'sstmsit', 'msit')]\n",
    "print(to_run)\n",
    "# to_fit = [('003', 'sstmsit', 'msit')]\n",
    "\n",
    "## joblib, also here careful with n_jobs\n",
    "Parallel(n_jobs=4, verbose=1)(delayed(fit_responsefinger_glm)(sub, ses, task) for sub, ses, task in to_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
