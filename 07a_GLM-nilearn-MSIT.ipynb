{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45bed63",
   "metadata": {},
   "source": [
    "# Script to analyse MSIT fMRI data through nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38afab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "import copy\n",
    "from utils import apply_warp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "tuples_to_run = [(x.split('/')[-2],x.split('/')[-1]) for x in sorted(glob.glob('../sourcedata/zipdata/sub*/ses*'))]\n",
    "tuples_to_run = [x for x in tuples_to_run if not x[0] == 'sub-001']\n",
    "\n",
    "for sub,ses in tuples_to_run:\n",
    "    glob.glob(f'../derivatives2/fmriprep/fmriprep/{sub}/{ses}/func/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57cbe7",
   "metadata": {},
   "source": [
    "## Model specifications\n",
    "### Model 0:\n",
    "- Con\n",
    "- Simon\n",
    "- Flanker\n",
    "- Inc\n",
    "\n",
    "### Model 1:\n",
    "- Response_index\n",
    "- Response_middle\n",
    "- Response_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_first_level_model_fn(sub, ses, task, smoothing_fwhm, model_n, space, save_dir_name='../derivatives/glm_nilearn/subject_level_model'):\n",
    "    smoothing_fwhm = str(smoothing_fwhm).replace('.', 'p')\n",
    "    return os.path.join(save_dir_name, f'sub-{sub}/ses-{ses}/func/fwhm-{smoothing_fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-first-level-model.pkl')\n",
    "\n",
    "## load\n",
    "def load_first_level_model(fn):\n",
    "    if os.path.exists(fn):\n",
    "        with open(fn, 'rb') as f:\n",
    "            first_level_model = pkl.load(f)  # protocol=4 required due to size of pkl\n",
    "        return first_level_model\n",
    "    else:\n",
    "        print(f'{fn} does not exist...')\n",
    "        return 0\n",
    "    \n",
    "def fit_first_level_model(sub, ses, task, model_n=0, space='MNI152NLin2009cAsym', include_physio=True, n_jobs=20, smoothing_fwhm=4.5, \n",
    "                          use_susan_presmoothed_data=True,\n",
    "                          save_model=True, save_dir_name='subject_level_model',\n",
    "                          overwrite=False, return_model=True):\n",
    "    # check for existing model\n",
    "    smoothing_fwhm_str = str(smoothing_fwhm).replace('.', 'p')\n",
    "    save_fn = make_first_level_model_fn(sub, ses, task, smoothing_fwhm, model_n, space, save_dir_name) # f'../derivatives/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{smoothing_fwhm_str}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-first-level-model.pkl'\n",
    "    if os.path.exists(save_fn) and not overwrite:\n",
    "        print(f'Model {model_n} {sub} {ses} {task} {smoothing_fwhm} already fit! Returning pre-fit model...')\n",
    "        if return_model:\n",
    "            return load_first_level_model(save_fn)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    event_fns = sorted(glob.glob(f'../derivatives/event_files/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_events.tsv'))\n",
    "#     regressor_fns = sorted(glob.glob(f'../derivatives/behavior/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_desc-model-regressors.tsv'))\n",
    "    confounds_fns = sorted(glob.glob(f'../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_desc-confounds_timeseries.tsv'))\n",
    "    \n",
    "    # fix this for susan presmoothed data\n",
    "    if use_susan_presmoothed_data:\n",
    "        smoothing_fwhm=None\n",
    "        func_fns = sorted(glob.glob(f'../derivatives/susan_smoothed_func/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_space-{space}_desc-preproc_bold_smoothed_fwhm-{smoothing_fwhm_str}.nii.gz'))\n",
    "    else:\n",
    "        func_fns = sorted(glob.glob(f'../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-*_space-{space}_desc-preproc_bold.nii.gz'))\n",
    "        \n",
    "    run_flms = []\n",
    "    run_events = []\n",
    "    run_funcs = []\n",
    "    run_confounds = []\n",
    "    \n",
    "    for run, (event_fn,  func_fn, confounds_fn) in enumerate(zip(event_fns, func_fns, confounds_fns)):    \n",
    "        # Merge events with trial-by-trial regressors\n",
    "        events = pd.read_csv(event_fn, sep='\\t', index_col=None)  # Onsets & event types\n",
    "        events['duration'] = 0.001  # stick functions\n",
    "        if model_n == 0:\n",
    "            events = events.loc[events.trial_type.isin(['con', 'simon', 'flanker', 'inc'])]\n",
    "        elif model_n == 1:\n",
    "            events = events.loc[events.trial_type.isin(['response_index', 'response_middle', 'response_ring'])]\n",
    "        events = events[['onset', 'trial_type', 'duration']]\n",
    "        \n",
    "        run_events.append(events)\n",
    "\n",
    "        # load func\n",
    "        func = nib.load(func_fn)\n",
    "        run_funcs.append(func)\n",
    "\n",
    "        # get confounds\n",
    "        confounds = pd.read_csv(confounds_fn, sep='\\t')[['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'dvars', 'framewise_displacement']].fillna(method='bfill')\n",
    "        \n",
    "        # get retroicor\n",
    "        if include_physio:\n",
    "            run_idx = run+1\n",
    "            retroicor_fn = f'../derivatives/retroicor/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-{run_idx}_desc-retroicor_regressors.tsv'\n",
    "            if not os.path.exists(retroicor_fn):\n",
    "                ## take first 20 aCompCor components\n",
    "                print(\"No retroicor found, including 20 a_comp_cor components\")\n",
    "                a_comp_cor = pd.read_csv(confounds_fn, sep='\\t')[['a_comp_cor_' + str(x).zfill(2) for x in range(20)]]\n",
    "                confounds = pd.concat([confounds, a_comp_cor], axis=1)\n",
    "            else:\n",
    "                retroicor = pd.read_csv(retroicor_fn, sep='\\t', header=None).iloc[:,:20]  ## 20 components in total\n",
    "                retroicor.columns = ['cardiac_' + str(x) for x in range(6)] + ['respiratory_' + str(x) for x in range(8)] + ['respiratoryxcardiac_' + str(x) for x in range(4)] + ['HRV', 'RVT']\n",
    "                confounds = pd.concat([confounds, retroicor], axis=1)\n",
    "\n",
    "        run_confounds.append(confounds)\n",
    "   \n",
    "    \n",
    "    # get brain mask\n",
    "    brain_mask = f'../derivatives/fmriprep/fmriprep/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_run-1_space-{space}_desc-brain_mask.nii.gz'\n",
    "    \n",
    "    # fit\n",
    "    flm = FirstLevelModel(t_r=1.38, hrf_model = 'glover + derivative', slice_time_ref=0.5,\n",
    "                          mask_img=brain_mask, smoothing_fwhm=smoothing_fwhm,\n",
    "                          n_jobs=n_jobs, subject_label=sub)\n",
    "    flm_fitted = flm.fit(run_funcs, events=run_events, confounds=run_confounds)\n",
    "    \n",
    "    # save\n",
    "    if save_model:\n",
    "        print('saving model to {}'.format(save_fn))\n",
    "        os.makedirs(os.path.dirname(save_fn), exist_ok=True)\n",
    "        with open(save_fn, 'wb') as f:\n",
    "            pkl.dump(flm_fitted, f, protocol=4)  # protocol=4 required due to size of pkl\n",
    "    \n",
    "    if return_model:\n",
    "        return flm_fitted\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83147b6c",
   "metadata": {},
   "source": [
    "# Which participants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f21412",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.compile('.*sub-(?P<sub>\\d+)_ses-sstmsit_task-msit_run-(?P<run>\\d).*')\n",
    "\n",
    "#all_func_files = sorted(glob.glob('../derivatives/fmriprep/fmriprep/sub-*/ses-rlsat/func/sub-*_ses-rlsat_task-rlsat_run-*_space-T1w_desc-preproc_bold.nii.gz'))\n",
    "all_func_files = sorted(glob.glob('../derivatives/fmriprep/fmriprep/sub-*/ses-sstmsit/func/sub-*_ses-sstmsit_task-msit_run-*_space-T1w_desc-preproc_bold.nii.gz'))\n",
    "func_file_df = pd.DataFrame([{**reg.match(x).groupdict(), **{'Func file': True}} for x in all_func_files])\n",
    "\n",
    "all_smoothed_func_files = sorted(glob.glob('../derivatives/susan_smoothed_func/sub-*/ses-sstmsit/func/*_task-msit*'))\n",
    "susan_file_df = pd.DataFrame([{**reg.match(x).groupdict(), **{'Susan smoothed': True}} for x in all_smoothed_func_files])\n",
    "\n",
    "all_retroicor_files = sorted(glob.glob('../derivatives/retroicor/sub-*/ses-sstmsit/func/sub-*_ses-sstmsit_task-msit_run-*_desc-retroicor_regressors.tsv'))\n",
    "retroicor_file_df = pd.DataFrame([{**reg.match(x).groupdict(), **{'Retroicor': True}} for x in all_retroicor_files])\n",
    "\n",
    "all_event_files = sorted(glob.glob('../derivatives/event_files/sub-*/ses-sstmsit/func/sub-*_ses-sstmsit_task-msit_run-*_events.tsv'))\n",
    "event_file_df = pd.DataFrame([{**reg.match(x).groupdict(), **{'Events': True}} for x in all_event_files])\n",
    "\n",
    "# all_behavior_files = sorted(glob.glob('../derivatives/behavior/sub-*/ses-sstmsit/func/sub-*_ses-rlsat_task-rlsat*'))\n",
    "# behav_file_df = pd.DataFrame([{**reg.match(x).groupdict(), **{'Behavior model': True}} for x in all_behavior_files])\n",
    "\n",
    "combined_df = pd.merge(pd.merge(pd.merge(func_file_df, susan_file_df, on=['sub', 'run'], how='outer'), \n",
    "                                         retroicor_file_df,on=['sub', 'run'], how='outer'), \n",
    "                                event_file_df, on=['sub', 'run'], how='outer')\n",
    "combined_df = combined_df.set_index(['sub', 'run']).fillna(False)\n",
    "combined_df['Complete'] = combined_df.apply(np.sum, axis=1) == 4\n",
    "\n",
    "with pd.option_context('display.max_rows', 10000):\n",
    "    display(combined_df.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fit = [(x, 'sstmsit', 'msit') for x in combined_df.loc[combined_df['Func file']].reset_index()['sub'].unique()]\n",
    "to_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f162d",
   "metadata": {},
   "source": [
    "# fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit # watch out for overwrite \n",
    "save_dir_name = '../derivatives/glm_nilearn/subject_level_model'\n",
    "space = 'T1w'\n",
    "\n",
    "def fit_glm(sub,ses,task, model_n, smoothing_fwhm, space='T1w'):\n",
    "    print(sub)\n",
    "    out = fit_first_level_model(sub, ses, task, model_n=model_n, space=space, overwrite=False, use_susan_presmoothed_data=True, smoothing_fwhm=smoothing_fwhm, save_dir_name=save_dir_name, return_model=False)\n",
    "    return out\n",
    "\n",
    "for model_n in [0, 1]: \n",
    "    for smoothing_fwhm in [4.5, 1.5]:\n",
    "        _ = joblib.Parallel(n_jobs=1)(joblib.delayed(fit_glm)(sub, ses, task, model_n=model_n, smoothing_fwhm=smoothing_fwhm) for sub,ses,task in to_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59fdfb",
   "metadata": {},
   "source": [
    "Compute & warp the contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea25c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrasts(comb, contrast_mapping, model_n, smoothing_fwhm, overwrite=False, space='T1w', save_dir_name='../derivatives/glm_nilearn/subject_level_model'):\n",
    "    sub,ses,task = comb\n",
    "    # check for existing model\n",
    "    smoothing_fwhm_str = str(smoothing_fwhm).replace('.', 'p')\n",
    "    flm_fn = make_first_level_model_fn(sub, ses, task, smoothing_fwhm, model_n, space, save_dir_name=save_dir_name)\n",
    "    if not os.path.exists(flm_fn):\n",
    "        raise(IOError(f\"Model doesn''t exist! expected to find it at {flm_fn}\"))\n",
    "        \n",
    "    # check for existing output fns\n",
    "    stat_map_name = 'z_score'\n",
    "    to_compute = {} #copy.copy(contrast_mapping)\n",
    "    for contrast_name, contrast in contrast_mapping.items():\n",
    "        save_fn = flm_fn.replace('desc-first-level-model.pkl', f'desc-contrast-{contrast_name}_{stat_map_name}.nii.gz')\n",
    "\n",
    "        if not os.path.exists(save_fn):\n",
    "            # skip this one\n",
    "            to_compute[contrast_name] = contrast\n",
    "\n",
    "        if os.path.exists(save_fn) and overwrite:\n",
    "            to_compute[contrast_name] = contrast\n",
    "    \n",
    "    if len(to_compute) == 0:\n",
    "        print(f'All contrasts for sub {sub} already computed')\n",
    "        return 0\n",
    "        \n",
    "    # load first level models & make contrast maps\n",
    "    first_level_model = load_first_level_model(flm_fn)\n",
    "\n",
    "    for contrast_name, contrast in to_compute.items():\n",
    "        \n",
    "        # save all stat maps\n",
    "        stat_maps = first_level_model.compute_contrast(contrast, output_type='all')\n",
    "        for stat_map_name, stat_map in stat_maps.items():\n",
    "            save_fn = flm_fn.replace('desc-first-level-model.pkl', f'desc-contrast-{contrast_name}_{stat_map_name}.nii.gz')\n",
    "            stat_map.to_filename(save_fn)\n",
    "            \n",
    "            # warp\n",
    "            stat_map_warped = apply_warp(save_fn, sub)            \n",
    "            # move\n",
    "            os.rename(stat_map_warped, save_fn.replace('space-T1w', 'space-MNI152NLin2009cAsym'))\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "save_dir_name = '../derivatives/glm_nilearn/subject_level_model'\n",
    "space = 'T1w'\n",
    "\n",
    "## weirdly this doesn't work with joblib, so move to multiprocess\n",
    "for model_n in [0, 1]: #,2]:\n",
    "    \n",
    "    if model_n == 0:\n",
    "#         contrast_mapping = {'con': 'fs',\n",
    "#                             'sml': 'ss',\n",
    "#                             'fll': 'go',\n",
    "#                             'fs-go': 'fs-go',\n",
    "#                             'ss-go': 'ss-go',\n",
    "#                             'fs-ss': 'fs-ss',\n",
    "#                             }\n",
    "        \n",
    "        contrast_mapping = {\n",
    "                            'Inc': 'inc',\n",
    "                            'Flanker': 'flanker',\n",
    "                            'Simon': 'simon',\n",
    "                            'Con': 'con',\n",
    "                            'Inc-Con': 'inc - con',\n",
    "                            'Inc-Flanker': 'inc - flanker',\n",
    "                            'Inc-Simon': 'inc - simon',\n",
    "                            'Flanker-Con': 'flanker - con',\n",
    "                            'Flanker-Simon': 'flanker - simon',\n",
    "                            'Simon-Con': 'simon - con'\n",
    "                            }\n",
    "        \n",
    "    elif model_n == 1:\n",
    "        contrast_mapping = {'Middle': 'response_middle',\n",
    "                            'Index': 'response_index',\n",
    "                            'Ring': 'response_ring',\n",
    "                            'Middle-Ring': 'response_middle - response_ring',\n",
    "                            'Middle-Index': 'response_middle - response_index',\n",
    "                            'Ring-Index': 'response_ring - response_index'\n",
    "                           }\n",
    "                            \n",
    "#         contrast_mapping = {'response_left': 'response_left',\n",
    "#                             'response_right': 'response_right',\n",
    "#                             'left-right': 'response_left - response_right'\n",
    "#                            }\n",
    "        \n",
    "    for smoothing_fwhm in [4.5, 1.5]:\n",
    "        with mp.Pool(8) as p:\n",
    "            p.map(partial(compute_contrasts, contrast_mapping=contrast_mapping, model_n=model_n, smoothing_fwhm=smoothing_fwhm, overwrite=False), to_fit)\n",
    "\n",
    "        # for comb in to_fit:        \n",
    "\n",
    "#             compute_contrasts(comb, contrast_mapping=contrast_mapping, model_n=model_n, smoothing_fwhm=smoothing_fwhm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e7e12",
   "metadata": {},
   "source": [
    "# plot individual sub contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc44fc",
   "metadata": {},
   "source": [
    "## first plot each contrast per sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_name = 'subject_level_model'\n",
    "\n",
    "space = 'T1w'\n",
    "susan = True\n",
    "# fwhm = '4p5' # or '1p5'\n",
    "\n",
    "# plot each contrast per sub\n",
    "# code is pretty slow cos it loads the t1w image\n",
    "# for fwhm in ['1p5','4p5']:\n",
    "#     for model_n in ['0','1']:\n",
    "        \n",
    "#         if model_n == '0':\n",
    "#             contrast_mapping = {\n",
    "#                                 'Inc': 'inc',\n",
    "#                                 'Flanker': 'flanker',\n",
    "#                                 'Simon': 'simon',\n",
    "#                                 'Con': 'con',\n",
    "#                                 'Inc-Con': 'inc - con',\n",
    "#                                 'Inc-Flanker': 'inc - flanker',\n",
    "#                                 'Inc-Simon': 'inc - simon',\n",
    "#                                 'Flanker-Con': 'flanker - con',\n",
    "#                                 'Flanker-Simon': 'flanker - simon',\n",
    "#                                 'Simon-Con': 'simon - con'\n",
    "#                                 }\n",
    "\n",
    "#         elif model_n == '1':\n",
    "#             contrast_mapping = {\n",
    "#                                 'Middle': 'response_middle',\n",
    "#                                 'Index': 'response_index',\n",
    "#                                 'Ring': 'response_ring',\n",
    "#                                 'Middle-Ring': 'response_middle - response_ring',\n",
    "#                                 'Middle-Index': 'response_middle - response_index',\n",
    "#                                 'Ring-Index': 'response_ring - response_index'\n",
    "#                                }\n",
    "\n",
    "def contrast_per_sub(comb, contrast_mapping, model_n, smoothing_fwhm, space, overwrite=False):\n",
    "    sub, ses, task = comb\n",
    "#     for sub, ses, task in to_fit:\n",
    "\n",
    "    if os.path.exists(f'../figures/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}') and not overwrite:\n",
    "        print(f'pdf for {sub} {ses} {fwhm} {model_n} already made, skipping..')\n",
    "        #continue \n",
    "\n",
    "    if not os.path.exists(f'../figures/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}') or overwrite:\n",
    "        os.makedirs(f'../figures/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/', exist_ok=True)\n",
    "\n",
    "        print(f'plotting sub {sub}')\n",
    "        f, ax = plt.subplots(len(contrast_mapping.items()),3, figsize=(20, 5*len(contrast_mapping.items())), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "        for counter, (contrast_name, contrast) in enumerate(contrast_mapping.items()):\n",
    "\n",
    "            if contrast in ['response_middle - response_ring','response_middle - response_index', 'response_ring - response_index']:\n",
    "                x,y,z = -33,-12,43\n",
    "            else:\n",
    "                x,y,z = 9,-16,-2\n",
    "\n",
    "            if not space == 'T1w':\n",
    "                t1w = 'MNI152TEMPLATE'\n",
    "            else:\n",
    "                t1w = f'/home/Public/trondheim/derivatives/fmriprep/fmriprep/sub-{sub}/anat/sub-{sub}_desc-preproc_T1w.nii.gz'\n",
    "\n",
    "    #                 if susan:\n",
    "    #                     z_map = f'../derivatives/glm_nilearn/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_susan_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "    #                 else:\n",
    "    #                     z_map = f'../derivatives/glm_nilearn/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "\n",
    "            z_map = f'../derivatives/glm_nilearn/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "\n",
    "            plotting.plot_stat_map(z_map, threshold=2.3, title=f'sub - {sub}, contrast - {contrast_name}', display_mode='x', cut_coords=[x], axes=ax[counter,0], colorbar=False, bg_img=t1w)\n",
    "            plotting.plot_stat_map(z_map, threshold=2.3,  display_mode='y', cut_coords=[y], axes=ax[counter,1], colorbar=False, bg_img=t1w)\n",
    "            plotting.plot_stat_map(z_map, threshold=2.3,  display_mode='z', cut_coords=[z],axes=ax[counter,2], bg_img=t1w)\n",
    "\n",
    "\n",
    "    #             if susan:\n",
    "    #                 plt.gcf().savefig(f'../figures/sub-{sub}/ses-{ses}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_susan_allContrasts-z_maps.pdf')\n",
    "    #             else:\n",
    "\n",
    "        plt.gcf().savefig(f'../figures/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}-allContrasts-z_maps.pdf')\n",
    "    \n",
    "    return 0\n",
    "\n",
    "        \n",
    "for model_n in ['0','1']:\n",
    "\n",
    "    if model_n == '0':\n",
    "        contrast_mapping = {\n",
    "                            'Inc': 'inc',\n",
    "                            'Flanker': 'flanker',\n",
    "                            'Simon': 'simon',\n",
    "                            'Con': 'con',\n",
    "                            'Inc-Con': 'inc - con',\n",
    "                            'Inc-Flanker': 'inc - flanker',\n",
    "                            'Inc-Simon': 'inc - simon',\n",
    "                            'Flanker-Con': 'flanker - con',\n",
    "                            'Flanker-Simon': 'flanker - simon',\n",
    "                            'Simon-Con': 'simon - con'\n",
    "                            }\n",
    "\n",
    "    elif model_n == '1':\n",
    "        contrast_mapping = {\n",
    "                            'Middle': 'response_middle',\n",
    "                            'Index': 'response_index',\n",
    "                            'Ring': 'response_ring',\n",
    "                            'Middle-Ring': 'response_middle - response_ring',\n",
    "                            'Middle-Index': 'response_middle - response_index',\n",
    "                            'Ring-Index': 'response_ring - response_index'\n",
    "                           }\n",
    "        \n",
    "    for fwhm in ['1p5','4p5']:    \n",
    "        with mp.Pool(8) as p:\n",
    "            #print(contrast_mapping)\n",
    "            p.map(partial(contrast_per_sub, contrast_mapping=contrast_mapping, model_n=model_n, smoothing_fwhm=fwhm, space=space, overwrite=False), to_fit)\n",
    "            \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500d057",
   "metadata": {},
   "source": [
    "## Second plot each sub per contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each sub per contrast\n",
    "# code is pretty slow cos it loads the t1w image\n",
    "# for susan in [True, False]:\n",
    "for fwhm in ['1p5','4p5']:\n",
    "    for model_n in ['0','1']:\n",
    "        \n",
    "        if model_n == '0':\n",
    "            contrast_mapping = {\n",
    "                                'Inc': 'inc',\n",
    "                                'Flanker': 'flanker',\n",
    "                                'Simon': 'simon',\n",
    "                                'Con': 'con',\n",
    "                                'Inc-Con': 'inc - con',\n",
    "                                'Inc-Flanker': 'inc - flanker',\n",
    "                                'Inc-Simon': 'inc - simon',\n",
    "                                'Flanker-Con': 'flanker - con',\n",
    "                                'Flanker-Simon': 'flanker - simon',\n",
    "                                'Simon-Con': 'simon - con'\n",
    "                                }\n",
    "\n",
    "        elif model_n == '1':\n",
    "            contrast_mapping = {\n",
    "                                'Middle': 'response_middle',\n",
    "                                'Index': 'response_index',\n",
    "                                'Ring': 'response_ring',\n",
    "                                'Middle-Ring': 'response_middle - response_ring',\n",
    "                                'Middle-Index': 'response_middle - response_index',\n",
    "                                'Ring-Index': 'response_ring - response_index'\n",
    "                               }\n",
    "        \n",
    "        for contrast_name, contrast in contrast_mapping.items():\n",
    "            print(f'plotting contrast {contrast_name}')\n",
    "            f, ax = plt.subplots(len(to_fit),3, figsize=(20, 5*len(to_fit)), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "            for counter, (sub, ses, task) in enumerate(to_fit):\n",
    "\n",
    "                if contrast in ['response_middle - response_ring','response_middle - response_index', 'response_ring - response_index']:\n",
    "                    x,y,z = -33,-12,43\n",
    "                else:\n",
    "                    x,y,z = 9,5,-2\n",
    "\n",
    "                if not space == 'T1w':\n",
    "                    t1w = 'MNI152TEMPLATE'\n",
    "                else:\n",
    "                    t1w = f'/home/Public/trondheim/derivatives/fmriprep/fmriprep/sub-{sub}/anat/sub-{sub}_desc-preproc_T1w.nii.gz'\n",
    "\n",
    "    #             if susan:\n",
    "    #                 z_map = f'../derivatives/{save_dir_name}/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_space-{space}_susan_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "    #             else:\n",
    "    #                 z_map = f'../derivatives/{save_dir_name}/sub-{sub}/ses-{ses}/func/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "                z_map = f'../derivatives/glm_nilearn/{save_dir_name}/sub-{sub}/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-{sub}_ses-{ses}_task-{task}_space-{space}_desc-contrast-{contrast_name}_z_score.nii.gz'\n",
    "\n",
    "                plotting.plot_stat_map(z_map, threshold=2.3, title=f'Contrast - {contrast_name}, sub - {sub}', display_mode='x', cut_coords=[x], axes=ax[counter,0], colorbar=False, bg_img=t1w)\n",
    "                plotting.plot_stat_map(z_map, threshold=2.3,  display_mode='y', cut_coords=[y], axes=ax[counter,1], colorbar=False, bg_img=t1w)\n",
    "                plotting.plot_stat_map(z_map, threshold=2.3,  display_mode='z', cut_coords=[z],axes=ax[counter,2], bg_img=t1w)\n",
    "\n",
    "            if not os.path.exists(f'../figures/sub-all/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}'):\n",
    "                os.makedirs(f'../figures/sub-all/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/')\n",
    "    #         if susan:\n",
    "    #             plt.gcf().savefig(f'../figures/sub-all/ses-{ses}/sub-ind_ses-{ses}_task-{task}_space-{space}_susan_{contrast_name}-z_maps.pdf', dpi=300,orientation='landscape')\n",
    "    #         else:\n",
    "    #             plt.gcf().savefig(f'../figures/sub-all/ses-{ses}/sub-ind_ses-{ses}_task-{task}_space-{space}-{contrast_name}-z_maps.pdf', dpi=300,orientation='landscape')\n",
    "\n",
    "            plt.gcf().savefig(f'../figures/sub-all/ses-{ses}/func/fwhm-{fwhm}/model-{model_n}/sub-ind_ses-{ses}_task-{task}_space-{space}-{contrast_name}-z_maps.pdf', dpi=300,orientation='landscape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c99c42",
   "metadata": {},
   "source": [
    "# Group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_second_level_spm(spm, first_level_contrast_name, second_level_contrast_name, fwhm, model_n, save_dir_name='../derivatives/glm_nilearn/group_level_model/ses-sstmsit'):\n",
    "    fwhm = str(fwhm).replace('.', 'p')\n",
    "    save_fn = os.path.join(save_dir_name, f'fwhm-{fwhm}/model-{model_n}/firstlevelcontrast-{first_level_contrast_name}_secondlevelcontrast-{second_level_contrast_name}.nii.gz')\n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(save_fn)):\n",
    "        os.makedirs(os.path.dirname(save_fn))\n",
    "    \n",
    "    spm.to_filename(save_fn)\n",
    "    nilearn.image.math_img('-nii', nii=spm).to_filename(save_fn.replace('.nii.gz', '-neg.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4edeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_second_level_models(first_level_contrast, second_level_contrast, fwhm, model_n, df):\n",
    "    print(f'{fwhm} {model_n} {first_level_contrast}')\n",
    "    df_in = df.loc[(df.map_name==first_level_contrast) & (df.fwhm==str(fwhm).replace('.', 'p')) & (df.model_n==str(model_n))]\n",
    "    #dm = pd.merge(df_in, parameters[['subject_label', 'B0.SPD-ACC_z']]) #, 'V0.SPD-ACC_z']])\n",
    "    df_in['intercept'] = 1\n",
    "\n",
    "    dm_in = df_in[['intercept']]\n",
    "#     if first_level_contrast == 'SPD-ACC':\n",
    "#         dm_in = dm[['intercept', 'B0.SPD-ACC_z']] #, 'V0.SPD-ACC_z']]\n",
    "#     else:\n",
    "#         dm_in = dm[['intercept']]\n",
    "    slm = SecondLevelModel()\n",
    "    slm_fitted = slm.fit(second_level_input=df_in.effects_map_path.values.tolist(), design_matrix=dm_in)\n",
    "\n",
    "    # Intercept, threshold covariance, urgency covariance\n",
    "    cmap = slm_fitted.compute_contrast('intercept', output_type='z_score')\n",
    "    save_second_level_spm(cmap, first_level_contrast_name=first_level_contrast, second_level_contrast_name=second_level_contrast, fwhm=fwhm, model_n=model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwhm = 1.5\n",
    "# fwhm_str = str(fwhm).replace('.', 'p')\n",
    "model_n = '0'\n",
    "\n",
    "imgs = sorted(glob.glob(f'../derivatives/glm_nilearn/subject_level_model/sub-*/ses-sstmsit/func/fwhm-*/model-{model_n}/*task-msit*MNI*desc-contrast-*_effect_size*'))\n",
    "regex = re.compile('.*/sub-(?P<sub>\\d+)/.*/fwhm-(?P<fwhm>\\S+)/model-(?P<model_n>\\d)/sub-.*_desc-contrast-(?P<contrast_name>\\S+)_effect_size.nii.gz')\n",
    "\n",
    "df = pd.DataFrame({'effects_map_path':imgs})\n",
    "df['subject_label'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['sub'])\n",
    "df['fwhm'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['fwhm'])\n",
    "df['model_n'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['model_n'])\n",
    "df['map_name'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['contrast_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combs = list(itertools.product(df.map_name.unique().tolist(), ['intercept'], [1.5], [0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(df.map_name.unique().tolist(), ['intercept'], [1.5], [0]))\n",
    "\n",
    "_ = joblib.Parallel(n_jobs=10, verbose=1)(joblib.delayed(fit_second_level_models)(first_level_contrast, second_level_contrast, fwhm, model_n, df=df) for first_level_contrast,second_level_contrast,fwhm,model_n in all_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c53ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2de14",
   "metadata": {},
   "source": [
    "# Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni09c = '/home/Public/trondheim/sourcedata/templates/mni_icbm152_t1_tal_nlin_asym_09c_brain.nii'\n",
    "                            'Inc': 'inc',\n",
    "                            'Flanker': 'flanker',\n",
    "                            'Simon': 'simon',\n",
    "                            'Con': 'con',\n",
    "                            'Inc-Con': 'inc - con',\n",
    "                            'Inc-Flanker': 'inc - flanker',\n",
    "                            'Inc-Simon': 'inc - simon',\n",
    "                            'Flanker-Con': 'flanker - con',\n",
    "                            'Flanker-Simon': 'flanker - simon',\n",
    "                            'Simon-Con': 'simon - con'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cd1b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in [3,0,2,1,4,5,6,7,8,9]:\n",
    "    first_level_contrast, second_level_contrast, fwhm, _ = all_combs[i]\n",
    "    fwhm = str(fwhm).replace('.', 'p')\n",
    "    z_map = nib.load(f'../derivatives/glm_nilearn/group_level_model/ses-sstmsit/fwhm-{fwhm}/model-0/firstlevelcontrast-{first_level_contrast}_secondlevelcontrast-{second_level_contrast}.nii.gz')\n",
    "    plotting.plot_stat_map(z_map, threshold=3.1, title=first_level_contrast, bg_img=mni09c, cut_coords=[-6, -13, 1], draw_cross=False)\n",
    "    plt.gcf().set_size_inches(15,6)\n",
    "    # plt.gcf().savefig(f'./msit-{first_level_contrast}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae94962",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fwhm = 1.5\n",
    "# fwhm_str = str(fwhm).replace('.', 'p')\n",
    "model_n = '1'\n",
    "\n",
    "imgs = sorted(glob.glob(f'../derivatives/glm_nilearn/subject_level_model/sub-*/ses-sstmsit/func/fwhm-*/model-{model_n}/*task-msit*MNI*desc-contrast-*_effect_size*'))\n",
    "regex = re.compile('.*/sub-(?P<sub>\\d+)/.*/fwhm-(?P<fwhm>\\S+)/model-(?P<model_n>\\d)/sub-.*_desc-contrast-(?P<contrast_name>\\S+)_effect_size.nii.gz')\n",
    "\n",
    "df = pd.DataFrame({'effects_map_path':imgs})\n",
    "df['subject_label'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['sub'])\n",
    "df['fwhm'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['fwhm'])\n",
    "df['model_n'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['model_n'])\n",
    "df['map_name'] = df.effects_map_path.apply(lambda x: regex.match(x).groupdict()['contrast_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11003c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_combs = list(itertools.product(df.map_name.unique().tolist(), ['intercept'], [1.5], [1]))\n",
    "\n",
    "_ = joblib.Parallel(n_jobs=10, verbose=1)(joblib.delayed(fit_second_level_models)(first_level_contrast, second_level_contrast, fwhm, model_n, df=df) for first_level_contrast,second_level_contrast,fwhm,model_n in all_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0779984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    first_level_contrast, second_level_contrast, fwhm, _ = all_combs[i]\n",
    "    fwhm = str(fwhm).replace('.', 'p')\n",
    "    z_map = nib.load(f'../derivatives/glm_nilearn/group_level_model/ses-sstmsit/fwhm-{fwhm}/model-1/firstlevelcontrast-{first_level_contrast}_secondlevelcontrast-{second_level_contrast}.nii.gz')\n",
    "    plotting.plot_stat_map(z_map, threshold=3.1, title=first_level_contrast, bg_img=mni09c, cut_coords=[-6, -13, 1], draw_cross=False)\n",
    "    plt.gcf().set_size_inches(15,6)\n",
    "    # plt.gcf().savefig(f'./msit-{first_level_contrast}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9f8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
